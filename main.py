import os
import torch
from scalable_model import create_overlock_model, ScalableOverLoCKModel
from rtx4090_configs import RTX4090OptimalConfig, RTX4090MaxConfig, get_rtx4090_training_config
from dataset import OverLoCKDataset
from trainer import OverLoCKTrainer


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ¡†æ¶"""

    # æ•°æ®é›†é€‰æ‹©: "cifar10" æˆ– "imagenet100"
    dataset_type = "imagenet100"  # ä¿®æ”¹è¿™é‡Œæ¥é€‰æ‹©æ•°æ®é›†
    
    if dataset_type == "imagenet100":
        print("ğŸ¯ ä½¿ç”¨ImageNet-100æ•°æ®é›† (100ç±», 224x224)")
        data_root = "./data/imagenet100"
        num_classes = 100
    else:
        print("ğŸ¯ ä½¿ç”¨CIFAR-10æ•°æ®é›† (10ç±», 224x224)")
        data_root = "./data"
        num_classes = 10

    # 1. è®¾ç½®å‚æ•° - RTX 4090æœ€ä¼˜åŒ–é…ç½®
    print("ğŸš€ ä½¿ç”¨RTX 4090æœ€ä¼˜åŒ–OverLoCKæ¨¡å‹é…ç½®")
    
    # æ£€æµ‹GPUæ•°é‡
    gpu_count = torch.cuda.device_count() if torch.cuda.is_available() else 0
    multi_gpu = gpu_count > 1
    
    if multi_gpu:
        print(f"ğŸ”¥ æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼Œå°†å¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒï¼")
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            print(f"  GPU {i}: {gpu_name}")
    else:
        print(f"ğŸ“± ä½¿ç”¨å•GPUè®­ç»ƒ (æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU)")
    
    # é€‰æ‹©æ¨¡å‹è§„æ¨¡: "optimal" æˆ– "max"
    model_size = "optimal"  # æ¨èä½¿ç”¨optimalï¼Œå¹³è¡¡æ€§èƒ½å’Œæ˜¾å­˜
    # model_size = "max"    # æœ€å¤§æ¨¡å‹ï¼Œ144Må‚æ•°ï¼Œéœ€è¦22GBæ˜¾å­˜
    
    if model_size == "max":
        print("ğŸ“Š ä½¿ç”¨MAXé…ç½®: ~144Må‚æ•°, é¢„æœŸæ˜¾å­˜ä½¿ç”¨: ~22GB")
        config = RTX4090MaxConfig()
    else:
        print("ğŸ“Š ä½¿ç”¨OPTIMALé…ç½®: ~65Må‚æ•°, é¢„æœŸæ˜¾å­˜ä½¿ç”¨: ~16GB")
        config = RTX4090OptimalConfig()
    
    # è·å–å¯¹åº”çš„è®­ç»ƒé…ç½®ï¼ˆåŒ…å«å¤šGPUæ”¯æŒï¼‰
    train_config = get_rtx4090_training_config(model_size, multi_gpu=multi_gpu)
    
    batch_size = train_config['batch_size']
    learning_rate = train_config['learning_rate']
    num_epochs = 3  # æ”¹ä¸º3ä¸ªepochï¼Œæ›´å®¹æ˜“çœ‹å‡ºæ€§èƒ½å·®å¼‚
    weight_decay = train_config['weight_decay']
    use_mixed_precision = train_config['use_mixed_precision']
    gradient_clip_max_norm = train_config['gradient_clip_max_norm']
    
    print(f"âš™ï¸ è®­ç»ƒé…ç½®: batch_size={batch_size}, lr={learning_rate}, epochs={num_epochs}")
    if multi_gpu:
        print(f"ğŸš€ åŒGPUæœ‰æ•ˆbatch_size: {batch_size * 2} (æ¯GPU: {batch_size})")
    print(f"ğŸ’¾ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ: {use_mixed_precision}")
    print(f"âš¡ æ¢¯åº¦è£å‰ª: {gradient_clip_max_norm}")
    
    # è®¾ç½®è®­ç»ƒæ¨¡å¼
    training_mode = "new"  # "new": é‡æ–°è®­ç»ƒ, "load": åªåŠ è½½æ¨¡å‹, "continue": ç»§ç»­è®­ç»ƒ
    checkpoint_path = f"./checkpoints/rtx4090_{model_size}_best_model.pth"  # ä¸“ç”¨è·¯å¾„

    # å®šä¹‰æ•°æ®å˜æ¢ - å¢åŠ æ•°æ®å¢å¼º
    from torchvision import transforms
    
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),  # å…ˆæ”¾å¤§
        transforms.RandomCrop((224, 224)),  # éšæœºè£å‰ª
        transforms.RandomHorizontalFlip(p=0.5),  # éšæœºæ°´å¹³ç¿»è½¬
        transforms.RandomRotation(degrees=15),  # éšæœºæ—‹è½¬
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # é¢œè‰²æŠ–åŠ¨
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # 2. åˆ›å»ºæ•°æ®é›†
    train_dataset = OverLoCKDataset(
        data_root=data_root,
        mode='train',
        transform=train_transform,
        dataset_type=dataset_type
    )

    val_dataset = OverLoCKDataset(
        data_root=data_root,
        mode='val',
        transform=val_transform,
        dataset_type=dataset_type
    )

    test_dataset = OverLoCKDataset(
        data_root=data_root,
        mode='test',
        transform=val_transform,
        dataset_type=dataset_type
    )

    # åŠ å…¥æµ‹è¯•é›†æ•°é‡æ£€æŸ¥
    print("=== æ•°æ®é›†ç»Ÿè®¡ ===")
    print(f"è®­ç»ƒé›†æ ·æœ¬æ•°é‡: {len(train_dataset)}")
    print(f"éªŒè¯é›†æ ·æœ¬æ•°é‡: {len(val_dataset)}")
    print("=" * 20)

    # è·å–å®é™…çš„ç±»åˆ«åç§°
    class_names = train_dataset.get_class_names()
    print(f"å®é™…ç±»åˆ«åç§°: {class_names}")
    print(f"ç±»åˆ«æ•°é‡: {len(class_names)}")

    # 3. åˆ›å»ºRTX 4090ä¼˜åŒ–æ¨¡å‹
    print(f"\nğŸ—ï¸ åˆ›å»º{model_size.upper()}è§„æ¨¡çš„OverLoCKæ¨¡å‹...")
    model = ScalableOverLoCKModel(
        class_names=class_names,
        config=config
    )

    # 4. æ‰“å°æ¨¡å‹ä¿¡æ¯
    print(f"\nğŸ“Š {config.name} Architecture:")
    model.print_model_info()
    
    # ä¼°ç®—æ˜¾å­˜ä½¿ç”¨
    total_params = sum(p.numel() for p in model.parameters())
    estimated_memory = train_config['memory_usage_gb']
    print(f"ğŸ’¾ é¢„ä¼°æ˜¾å­˜ä½¿ç”¨: {estimated_memory:.1f} GB (RTX 4090: 24GB)")
    print(f"ğŸ¯ æ˜¾å­˜åˆ©ç”¨ç‡: {estimated_memory/24*100:.1f}%")
    
    if model_size == "max":
        print("âš ï¸ MAXé…ç½®éœ€è¦å¤§é‡æ˜¾å­˜ï¼Œç¡®ä¿RTX 4090æœ‰è¶³å¤Ÿçš„æ˜¾å­˜ç©ºé—´")
    else:
        print("âœ… OPTIMALé…ç½®æ˜¾å­˜ä½¿ç”¨é€‚ä¸­ï¼Œæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ")

    # 5. æ ¹æ®è®­ç»ƒæ¨¡å¼é€‰æ‹©æ“ä½œ
    if training_mode == "load" and os.path.exists(checkpoint_path):
        print(f"\nğŸ”„ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {checkpoint_path}")
        # åªåŠ è½½æ¨¡å‹æƒé‡ï¼Œä¸è®­ç»ƒ
        checkpoint = torch.load(checkpoint_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        
        # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)
        
        print(f"âœ… æ¨¡å‹å·²åŠ è½½ï¼ŒéªŒè¯å‡†ç¡®ç‡: {checkpoint.get('val_acc', 'N/A'):.2f}%")
        print(f"ğŸ“Š å·²å®Œæˆè®­ç»ƒè½®æ•°: {checkpoint.get('epoch', 'N/A') + 1}")
        
    elif training_mode == "continue" and os.path.exists(checkpoint_path):
        print(f"\nğŸ”„ ç»§ç»­è®­ç»ƒæ¨¡å¼: ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ")
        print(f"ğŸ“‚ æ£€æŸ¥ç‚¹è·¯å¾„: {checkpoint_path}")
        
        # åˆ›å»ºè®­ç»ƒå™¨ - å¤šGPUæ”¯æŒ
        trainer = OverLoCKTrainer(
            model=model,
            train_dataset=train_dataset,
            val_dataset=val_dataset,
            batch_size=batch_size,
            learning_rate=learning_rate,
            num_epochs=num_epochs,
            device='cuda',
            save_dir='./checkpoints',
            clip_loss_weight=0.1,  # X-Largeæ¨¡å‹ç”¨è¾ƒå°çš„CLIPæƒé‡
            multi_gpu=multi_gpu
        )
        
        # åº”ç”¨RTX 4090ä¼˜åŒ–è®¾ç½®
        trainer.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay,
            betas=(0.9, 0.999)
        )
        
        # åŠ è½½æ£€æŸ¥ç‚¹å¹¶ç»§ç»­è®­ç»ƒ
        start_epoch, current_val_acc = trainer.load_checkpoint(checkpoint_path)
        print(f"âœ… æ£€æŸ¥ç‚¹å·²åŠ è½½")
        print(f"ğŸ“Š å½“å‰éªŒè¯å‡†ç¡®ç‡: {current_val_acc:.2f}%")
        print(f"ğŸ”¢ å·²å®Œæˆè½®æ•°: {start_epoch + 1}")
        print(f"ğŸ“ˆ è®­ç»ƒå†å²å·²æ¢å¤ï¼ŒåŒ…å« {len(trainer.history['train_loss'])} ä¸ªè®­ç»ƒè®°å½•")
        
        print("\n" + "="*60)
        print(f"ç»§ç»­è®­ç»ƒ - ä»ç¬¬ {start_epoch + 2} è½®å¼€å§‹")
        print("="*60)
        # ç»§ç»­è®­ç»ƒ
        trainer.train()
        
    elif training_mode == "new":
        print("\nğŸ†• å¼€å§‹X-Largeæ¨¡å‹å…¨æ–°è®­ç»ƒ...")
        # åˆ›å»ºè®­ç»ƒå™¨ - å¤šGPUæ”¯æŒ
        trainer = OverLoCKTrainer(
            model=model,
            train_dataset=train_dataset,
            val_dataset=val_dataset,
            batch_size=batch_size,
            learning_rate=learning_rate,
            num_epochs=num_epochs,
            device='cuda',
            save_dir='./checkpoints',
            clip_loss_weight=0.1,
            multi_gpu=multi_gpu
        )
        
        print(f"ğŸš€ å¤šGPUæ¨¡å‹è®­ç»ƒå™¨å·²åˆ›å»º")
        if multi_gpu:
            print(f"âš¡ åŒGPUè®­ç»ƒï¼šbatch_size={batch_size} (æ¯GPUçº¦{batch_size//2})")
            print(f"ğŸ’¾ é¢„æœŸæ˜¾å­˜ä½¿ç”¨: {estimated_memory:.1f} GB Ã— 2 = {estimated_memory*2:.1f} GB")
        print(f"ï¿½ å­¦ä¹ ç‡: {learning_rate} (è®ºæ–‡æ¨è)")
        print(f"âš–ï¸ æƒé‡è¡°å‡: {weight_decay} (è®ºæ–‡æ¨è)")
        print(f"â±ï¸ é¢„æœŸè®­ç»ƒæ—¶é—´: 2-5åˆ†é’Ÿ (1è½®æµ‹è¯•)")
        
        print("\n" + "="*60)
        print("å¼€å§‹X-Large OverLoCKæ¨¡å‹è®­ç»ƒ (RTX 4090ä¼˜åŒ–) - æµ‹è¯•æ¨¡å¼")
        print("="*60)
        print(f"ğŸš€ æ¨¡å‹è§„æ¨¡: {total_params/1e6:.1f}M å‚æ•°")
        print(f"ğŸ’¾ æ˜¾å­˜ä½¿ç”¨: ~{estimated_memory:.1f} GB")
        print(f"â±ï¸ é¢„æœŸæ—¶é—´: 5-10åˆ†é’Ÿ (1è½®æµ‹è¯•)")
        # å¼€å§‹è®­ç»ƒ
        trainer.train()
        
    else:
        if training_mode == "continue":
            print(f"\nâš ï¸  ç»§ç»­è®­ç»ƒæ¨¡å¼ä½†æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹: {checkpoint_path}")
            print("ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°å…¨æ–°è®­ç»ƒæ¨¡å¼")
        elif training_mode == "load":
            print(f"\nâš ï¸  åŠ è½½æ¨¡å¼ä½†æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹: {checkpoint_path}")
            print("ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°å…¨æ–°è®­ç»ƒæ¨¡å¼")
            
        print("\nğŸ†• å¼€å§‹X-Largeæ¨¡å‹å…¨æ–°è®­ç»ƒ...")
        # åˆ›å»ºè®­ç»ƒå™¨ - å¤šGPUæ”¯æŒ
        trainer = OverLoCKTrainer(
            model=model,
            train_dataset=train_dataset,
            val_dataset=val_dataset,
            batch_size=batch_size,
            learning_rate=learning_rate,
            num_epochs=num_epochs,
            device='cuda',
            save_dir='./checkpoints',
            clip_loss_weight=0.1,
            multi_gpu=multi_gpu
        )
        
        print(f"ğŸš€ å¤šGPUæ¨¡å‹è®­ç»ƒå™¨å·²åˆ›å»º")
        if multi_gpu:
            print(f"âš¡ åŒGPUè®­ç»ƒï¼šbatch_size={batch_size} (æ¯GPUçº¦{batch_size//2})")
            print(f"ğŸ’¾ é¢„æœŸæ˜¾å­˜ä½¿ç”¨: {estimated_memory:.1f} GB Ã— 2 = {estimated_memory*2:.1f} GB")
        print(f"ğŸ“ˆ å­¦ä¹ ç‡: {learning_rate} (è®ºæ–‡æ¨è)")
        print(f"âš–ï¸ æƒé‡è¡°å‡: {weight_decay} (è®ºæ–‡æ¨è)")
        print(f"â±ï¸ é¢„æœŸè®­ç»ƒæ—¶é—´: 2-5åˆ†é’Ÿ (1è½®æµ‹è¯•)")
        
        print("\n" + "="*60)
        if multi_gpu:
            print("å¼€å§‹OverLoCKæ¨¡å‹åŒGPUå¹¶è¡Œè®­ç»ƒ - æµ‹è¯•æ¨¡å¼")
        else:
            print("å¼€å§‹OverLoCKæ¨¡å‹è®­ç»ƒ - æµ‹è¯•æ¨¡å¼")
        print("="*60)
        print(f"ğŸš€ æ¨¡å‹è§„æ¨¡: {total_params/1e6:.1f}M å‚æ•°")
        print(f"ğŸ’¾ æ˜¾å­˜ä½¿ç”¨: ~{estimated_memory:.1f} GB" + (f" Ã— 2" if multi_gpu else ""))
        print(f"â±ï¸ é¢„æœŸæ—¶é—´: 2-5åˆ†é’Ÿ (1è½®æµ‹è¯•)")
        # å¼€å§‹è®­ç»ƒ
        trainer.train()

    # 6. æµ‹è¯•æ¨ç†(æ‰¹é‡å¤„ç†ç¤ºä¾‹) - ä½¿ç”¨test_datasetçš„éšæœºæ•°æ®
    model.eval()
    with torch.no_grad():
        # ä»éªŒè¯é›†ä¸­éšæœºé€‰æ‹©8ä¸ªæ ·æœ¬
        import random
        import json
        import matplotlib.pyplot as plt
        import warnings
        from torchvision import transforms
        from PIL import Image
        import numpy as np
        
        # æŠ‘åˆ¶matplotlibå­—ä½“è­¦å‘Š
        warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“å‡½æ•°
        def setup_chinese_font():
            """è®¾ç½®ä¸­æ–‡å­—ä½“ - ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿä¸­æ–‡å­—ä½“"""
            import matplotlib.font_manager as fm
            
            # å°è¯•æœ¬åœ°å­—ä½“æ–‡ä»¶è·¯å¾„
            font_paths = [
                '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
                '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',
                './fonts/NotoSansCJK-Regular.ttc',
                './fonts/NotoSansSC-Regular.ttf',
                '/System/Library/Fonts/PingFang.ttc',  # macOS
                'C:/Windows/Fonts/msyh.ttc',  # Windows å¾®è½¯é›…é»‘
                'C:/Windows/Fonts/simhei.ttf'  # Windows é»‘ä½“
            ]
            
            # é¦–å…ˆå°è¯•æœ¬åœ°å­—ä½“æ–‡ä»¶
            for font_path in font_paths:
                if os.path.exists(font_path):
                    try:
                        font_prop = fm.FontProperties(fname=font_path)
                        fm.fontManager.addfont(font_path)
                        font_name = font_prop.get_name()
                        
                        # å¼ºåˆ¶è®¾ç½®å­—ä½“
                        plt.rcParams['font.family'] = font_name
                        plt.rcParams['axes.unicode_minus'] = False
                        
                        print(f"âœ… ä½¿ç”¨æœ¬åœ°ä¸­æ–‡å­—ä½“: {font_name} ({font_path})")
                        return True
                    except Exception as e:
                        print(f"âš ï¸  å­—ä½“æ–‡ä»¶ {font_path} åŠ è½½å¤±è´¥: {e}")
                        continue
            
            # ç³»ç»Ÿä¸­æ–‡å­—ä½“åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            chinese_fonts = [
                'Noto Sans CJK SC',
                'WenQuanYi Micro Hei',
                'SimHei',
                'Microsoft YaHei',
                'PingFang SC',
                'Hiragino Sans GB',
                'Source Han Sans CN',
                'Noto Sans SC'
            ]
            
            # å°è¯•ç³»ç»Ÿå­—ä½“åç§°
            for font_name in chinese_fonts:
                try:
                    plt.rcParams['font.family'] = font_name
                    plt.rcParams['axes.unicode_minus'] = False
                    
                    # æµ‹è¯•å­—ä½“æ˜¯å¦å¯ç”¨
                    fig, ax = plt.subplots(figsize=(1, 1))
                    ax.text(0.5, 0.5, 'æµ‹è¯•ä¸­æ–‡', fontsize=12, fontfamily=font_name)
                    plt.close(fig)
                    
                    print(f"âœ… ä½¿ç”¨ç³»ç»Ÿä¸­æ–‡å­—ä½“: {font_name}")
                    return True
                except Exception as e:
                    print(f"âš ï¸  å­—ä½“ {font_name} ä¸å¯ç”¨: {e}")
                    continue
            
            # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
            plt.rcParams['font.family'] = ['sans-serif']
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            print("âš ï¸  ä½¿ç”¨é»˜è®¤å­—ä½“ï¼Œä¸­æ–‡å¯èƒ½æ˜¾ç¤ºä¸ºæ–¹æ¡†")
            return False
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        setup_chinese_font()
        
        # åˆ›å»ºç»“æœä¿å­˜ç›®å½•
        result_dir = "./result"
        os.makedirs(result_dir, exist_ok=True)
        
        # å®šä¹‰å›¾åƒé¢„å¤„ç†
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # éšæœºé€‰æ‹©æ ·æœ¬ç´¢å¼•
        batch_size = 100
        random_indices = random.sample(range(len(val_dataset)), min(batch_size, len(val_dataset)))
        
        test_images = []
        test_labels = []
        test_paths = []
        original_images = []  # ä¿å­˜åŸå§‹å›¾åƒç”¨äºå¯è§†åŒ–
        
        # åˆ›å»ºä¸€ä¸ªæ²¡æœ‰transformçš„æ•°æ®é›†æ¥è·å–åŸå§‹å›¾åƒ
        val_dataset_no_transform = OverLoCKDataset(
            data_root=data_root,  # ä½¿ç”¨æ­£ç¡®çš„data_root
            mode='val',
            transform=None,
            dataset_type=dataset_type  # ä½¿ç”¨æ­£ç¡®çš„dataset_type
        )
        
        # ç¡®ä¿ä¸¤ä¸ªæ•°æ®é›†é•¿åº¦ä¸€è‡´
        max_samples = min(len(val_dataset), len(val_dataset_no_transform))
        random_indices = random.sample(range(max_samples), min(batch_size, max_samples))
        
        for idx in random_indices:
            # æ£€æŸ¥ç´¢å¼•èŒƒå›´å®‰å…¨æ€§
            if idx < len(val_dataset) and idx < len(val_dataset_no_transform):
                # è·å–å·²ç»å˜æ¢çš„å›¾åƒå’Œæ ‡ç­¾
                image, label = val_dataset[idx]
                test_images.append(image)
                test_labels.append(label)
                test_paths.append(val_dataset.samples[idx][0])  # è·å–å›¾åƒè·¯å¾„
                
                # è·å–åŸå§‹å›¾åƒç”¨äºå¯è§†åŒ–
                original_image, _ = val_dataset_no_transform[idx]
                original_images.append(original_image)
        
        # åˆ›å»ºæ‰¹é‡æ•°æ®
        test_batch = torch.stack(test_images)
        test_labels = torch.tensor(test_labels)
        
        if torch.cuda.is_available():
            test_batch = test_batch.cuda()
            test_labels = test_labels.cuda()
            model = model.cuda()

        # æ¨ç†
        logits, clip_logits = model(test_batch)
        predictions = torch.argmax(logits, dim=1)
        
        # è®¡ç®—æ­£ç¡®ç‡
        correct = (predictions.cpu() == test_labels.cpu()).sum().item()
        accuracy = correct / len(test_labels) * 100

        print("\nInference Test (using val_dataset random samples):")
        print(f"Input shape: {test_batch.shape}")
        print(f"Output logits shape: {logits.shape}")
        print(f"Predictions: {predictions.cpu().numpy()}")
        print(f"Ground truth: {test_labels.cpu().numpy()}")
        print(f"Accuracy: {accuracy:.2f}% ({correct}/{len(test_labels)})")
        
        # ä¿å­˜é¢„æµ‹ç»“æœåˆ°JSONæ–‡ä»¶
        results = []
        for i in range(len(predictions)):
            pred_class = class_names[predictions[i].cpu().item()]
            true_class = class_names[test_labels[i].cpu().item()]
            image_path = os.path.basename(test_paths[i])
            is_correct = predictions[i].cpu().item() == test_labels[i].cpu().item()
            
            result = {
                "sample_id": i + 1,
                "image_name": image_path,
                "predicted_class": pred_class,
                "true_class": true_class,
                "is_correct": is_correct,
                "confidence": torch.softmax(logits[i], dim=0).max().cpu().item()
            }
            results.append(result)
        
        # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
        with open(os.path.join(result_dir, "inference_results.json"), "w", encoding="utf-8") as f:
            json.dump({
                "accuracy": accuracy,
                "total_samples": len(test_labels),
                "correct_predictions": correct,
                "results": results
            }, f, indent=2, ensure_ascii=False)
        
        # åˆ›å»ºå¯è§†åŒ–å›¾åƒ - æ˜¾ç¤ºå‰16ä¸ªæ ·æœ¬ä½œä¸ºç¤ºä¾‹
        display_count = min(16, len(predictions))
        fig, axes = plt.subplots(4, 4, figsize=(20, 20))
        fig.suptitle(f'Inference Results Sample (showing {display_count}/{len(predictions)}) - Accuracy: {accuracy:.2f}%', fontsize=16)
        
        for i in range(display_count):
            row = i // 4
            col = i % 4
            
            # æ˜¾ç¤ºåŸå§‹å›¾åƒ
            axes[row, col].imshow(original_images[i])
            axes[row, col].axis('off')
            
            # è®¾ç½®æ ‡é¢˜
            pred_class = class_names[predictions[i].cpu().item()]
            true_class = class_names[test_labels[i].cpu().item()]
            is_correct = predictions[i].cpu().item() == test_labels[i].cpu().item()
            confidence = torch.softmax(logits[i], dim=0).max().cpu().item()
            
            title_color = 'green' if is_correct else 'red'
            title = f'#{i+1} Pred: {pred_class}\nTrue: {true_class}\nConf: {confidence:.3f}'
            axes[row, col].set_title(title, color=title_color, fontsize=10)
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        plt.tight_layout()
        plt.savefig(os.path.join(result_dir, "inference_visualization.png"), dpi=300, bbox_inches='tight')
        plt.close()
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœè¯¦æƒ…
        print("\nDetailed predictions:")
        for result in results:
            status = "âœ“" if result["is_correct"] else "âœ—"
            print(f"Sample {result['sample_id']}: {result['image_name']} -> "
                  f"Predicted: {result['predicted_class']}, True: {result['true_class']} "
                  f"[Conf: {result['confidence']:.3f}] {status}")
        
        print(f"\nResults saved to: {result_dir}/")
        print(f"- inference_results.json: Detailed results in JSON format")
        print(f"- inference_visualization.png: Visual results with sample images (showing first 16)")


if __name__ == "__main__":
    main()
