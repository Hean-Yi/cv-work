#!/usr/bin/env python3
"""
é’ˆå¯¹RTX 4090ä¼˜åŒ–çš„è®­ç»ƒé…ç½®
å……åˆ†åˆ©ç”¨24GBæ˜¾å­˜ï¼Œæä¾›ä¸åŒæ¨¡å‹è§„æ¨¡çš„æœ€ä¼˜è®­ç»ƒå‚æ•°
"""

class RTX4090TrainingConfig:
    """RTX 4090ä¼˜åŒ–è®­ç»ƒé…ç½®"""
    
    # åŸºç¡€é…ç½®
    DEVICE = 'cuda'
    NUM_WORKERS = 8  # 4090é…åˆé«˜æ€§èƒ½CPUæ—¶çš„æœ€ä½³çº¿ç¨‹æ•°
    PIN_MEMORY = True
    PERSISTENT_WORKERS = True  # å‡å°‘workeré‡å¯å¼€é”€
    
    # å°æ¨¡å‹é…ç½® (3-6Må‚æ•°)
    SMALL_MODEL_CONFIG = {
        'batch_size': 128,  # å¤§batch sizeæé«˜è®­ç»ƒæ•ˆç‡
        'learning_rate': 2e-4,  # å¤§batch sizeå¯¹åº”æ›´é«˜çš„å­¦ä¹ ç‡
        'weight_decay': 1e-4,
        'gradient_clip_max_norm': 1.0,
        'use_mixed_precision': True,  # èŠ‚çœæ˜¾å­˜ï¼ŒåŠ é€Ÿè®­ç»ƒ
        'compile_model': True,  # PyTorch 2.0ç¼–è¯‘åŠ é€Ÿ
        'memory_usage_gb': 2.0,  # é¢„æœŸæ˜¾å­˜ä½¿ç”¨
    }
    
    # ä¸­ç­‰æ¨¡å‹é…ç½® (8-15Må‚æ•°)
    MEDIUM_MODEL_CONFIG = {
        'batch_size': 64,
        'learning_rate': 1.5e-4,
        'weight_decay': 1e-4,
        'gradient_clip_max_norm': 1.0,
        'use_mixed_precision': True,
        'compile_model': True,
        'memory_usage_gb': 4.5,
    }
    
    # å¤§æ¨¡å‹é…ç½® (20-30Må‚æ•°)
    LARGE_MODEL_CONFIG = {
        'batch_size': 48,
        'learning_rate': 1e-4,
        'weight_decay': 2e-4,  # å¤§æ¨¡å‹éœ€è¦æ›´å¼ºçš„æ­£åˆ™åŒ–
        'gradient_clip_max_norm': 1.0,
        'use_mixed_precision': True,
        'compile_model': True,
        'gradient_checkpointing': False,  # 4090æ˜¾å­˜å……è¶³ï¼Œä¼˜å…ˆé€Ÿåº¦
        'memory_usage_gb': 8.0,
    }
    
    # è¶…å¤§æ¨¡å‹é…ç½® (40M+å‚æ•°)
    XLARGE_MODEL_CONFIG = {
        'batch_size': 32,
        'learning_rate': 8e-5,
        'weight_decay': 3e-4,
        'gradient_clip_max_norm': 0.5,  # å¤§æ¨¡å‹æ¢¯åº¦æ›´å®¹æ˜“çˆ†ç‚¸
        'use_mixed_precision': True,
        'compile_model': True,
        'gradient_checkpointing': True,  # å¿…è¦æ—¶å¯ç”¨ä»¥èŠ‚çœæ˜¾å­˜
        'memory_usage_gb': 16.0,
    }
    
    # å­¦ä¹ ç‡è°ƒåº¦é…ç½®
    SCHEDULER_CONFIG = {
        'type': 'cosine_with_warmup',
        'warmup_epochs': 5,
        'cosine_restarts': True,
        'restart_period': 50,
        'min_lr_factor': 0.01,
    }
    
    # æ•°æ®å¢å¼ºé…ç½® (é’ˆå¯¹CIFAR-10ç­‰å°å›¾åƒ)
    DATA_AUGMENTATION_CONFIG = {
        'horizontal_flip': True,
        'vertical_flip': False,
        'rotation_degrees': 15,
        'color_jitter': {
            'brightness': 0.2,
            'contrast': 0.2,
            'saturation': 0.2,
            'hue': 0.1
        },
        'random_erasing': {
            'probability': 0.25,
            'scale': (0.02, 0.33),
            'ratio': (0.3, 3.3),
        },
        'cutmix': {
            'probability': 0.5,
            'alpha': 1.0,
        },
        'mixup': {
            'probability': 0.5,
            'alpha': 0.8,
        }
    }
    
    # ä¼˜åŒ–å™¨é…ç½®
    OPTIMIZER_CONFIG = {
        'type': 'adamw',  # å¯é€‰: 'adamw', 'lion', 'sgd'
        'betas': (0.9, 0.999),
        'eps': 1e-8,
        'amsgrad': False,
    }
    
    # æŸå¤±å‡½æ•°é…ç½®
    LOSS_CONFIG = {
        'primary_loss': 'cross_entropy',
        'label_smoothing': 0.1,  # æé«˜æ³›åŒ–èƒ½åŠ›
        'clip_loss_weight': 0.1,  # CLIPè¾…åŠ©æŸå¤±æƒé‡
    }
    
    # æ—©åœå’Œæ£€æŸ¥ç‚¹é…ç½®
    CHECKPOINT_CONFIG = {
        'save_every_epochs': 10,
        'keep_best_n': 3,
        'early_stopping_patience': 15,
        'early_stopping_min_delta': 0.001,
    }

def get_training_config_for_model_size(model_params_millions):
    """æ ¹æ®æ¨¡å‹å‚æ•°é‡è·å–æœ€ä¼˜è®­ç»ƒé…ç½®"""
    config = RTX4090TrainingConfig()
    
    if model_params_millions < 8:
        return config.SMALL_MODEL_CONFIG
    elif model_params_millions < 20:
        return config.MEDIUM_MODEL_CONFIG
    elif model_params_millions < 40:
        return config.LARGE_MODEL_CONFIG
    else:
        return config.XLARGE_MODEL_CONFIG

def estimate_training_time(model_params_millions, num_epochs=100, dataset_size=50000):
    """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
    config = get_training_config_for_model_size(model_params_millions)
    batch_size = config['batch_size']
    
    # åŸºäºç»éªŒçš„æ—¶é—´ä¼°ç®— (RTX 4090)
    batches_per_epoch = dataset_size // batch_size
    
    # æ¯batchå¤„ç†æ—¶é—´ä¼°ç®— (æ¯«ç§’)
    if model_params_millions < 8:
        ms_per_batch = 50  # å°æ¨¡å‹å¾ˆå¿«
    elif model_params_millions < 20:
        ms_per_batch = 80
    elif model_params_millions < 40:
        ms_per_batch = 120
    else:
        ms_per_batch = 200  # å¤§æ¨¡å‹è¾ƒæ…¢ä½†ä»ç„¶å¾ˆå¿«
    
    total_time_hours = (batches_per_epoch * num_epochs * ms_per_batch) / (1000 * 3600)
    
    return {
        'estimated_hours': total_time_hours,
        'batches_per_epoch': batches_per_epoch,
        'ms_per_batch': ms_per_batch,
        'recommended_batch_size': batch_size
    }

def print_training_recommendations():
    """æ‰“å°RTX 4090è®­ç»ƒå»ºè®®"""
    print("=" * 80)
    print("RTX 4090 OverLoCKæ¨¡å‹è®­ç»ƒä¼˜åŒ–å»ºè®®")
    print("=" * 80)
    
    model_sizes = [
        ("Small (3-6Må‚æ•°)", 4),
        ("Medium (8-15Må‚æ•°)", 12),
        ("Large (20-30Må‚æ•°)", 25),
        ("X-Large (40M+å‚æ•°)", 45)
    ]
    
    for name, params_m in model_sizes:
        config = get_training_config_for_model_size(params_m)
        time_est = estimate_training_time(params_m)
        
        print(f"\n{name}:")
        print(f"  â€¢ æ¨èbatch_size: {config['batch_size']}")
        print(f"  â€¢ æ¨èå­¦ä¹ ç‡: {config['learning_rate']}")
        print(f"  â€¢ é¢„æœŸæ˜¾å­˜ä½¿ç”¨: {config['memory_usage_gb']:.1f} GB")
        print(f"  â€¢ é¢„æœŸè®­ç»ƒæ—¶é—´: {time_est['estimated_hours']:.1f} å°æ—¶ (100 epochs)")
        print(f"  â€¢ æ¯æ‰¹å¤„ç†æ—¶é—´: {time_est['ms_per_batch']} ms")
        
    print("\n" + "=" * 80)
    print("é€šç”¨ä¼˜åŒ–å»ºè®®:")
    print("=" * 80)
    print("ğŸš€ æ€§èƒ½ä¼˜åŒ–:")
    print("   â€¢ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (torch.cuda.amp)")
    print("   â€¢ ä½¿ç”¨torch.compile()ç¼–è¯‘æ¨¡å‹ (PyTorch 2.0+)")
    print("   â€¢ è®¾ç½®num_workers=8ï¼Œpin_memory=True")
    print("   â€¢ ä½¿ç”¨persistent_workers=Trueå‡å°‘é‡å¯å¼€é”€")
    
    print("\nğŸ’¾ æ˜¾å­˜ä¼˜åŒ–:")
    print("   â€¢ å¯¹äºè¶…å¤§æ¨¡å‹å¯ç”¨gradient_checkpointing")
    print("   â€¢ ä½¿ç”¨æ›´é«˜æ•ˆçš„ä¼˜åŒ–å™¨å¦‚Lion (å¯é€‰)")
    print("   â€¢ åˆç†è®¾ç½®batch_sizeå……åˆ†åˆ©ç”¨æ˜¾å­˜")
    
    print("\nğŸ“Š è®­ç»ƒç­–ç•¥:")
    print("   â€¢ ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦+é¢„çƒ­")
    print("   â€¢ æ·»åŠ æ ‡ç­¾å¹³æ»‘(0.1)æé«˜æ³›åŒ–")
    print("   â€¢ ä½¿ç”¨æ•°æ®å¢å¼º: Cutmix + Mixup + RandomErasing")
    print("   â€¢ è®¾ç½®æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸")
    
    print("\nâ° è®­ç»ƒæ—¶é—´ä¼°ç®— (CIFAR-10, 100 epochs):")
    print("   â€¢ Smallæ¨¡å‹: 1-2å°æ—¶")
    print("   â€¢ Mediumæ¨¡å‹: 3-4å°æ—¶") 
    print("   â€¢ Largeæ¨¡å‹: 6-8å°æ—¶")
    print("   â€¢ X-Largeæ¨¡å‹: 12-15å°æ—¶")
    
    print("\nğŸ¯ æœ€ä½³å®è·µ:")
    print("   â€¢ ä½¿ç”¨tensorboardç›‘æ§è®­ç»ƒè¿‡ç¨‹")
    print("   â€¢ å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼Œä¿ç•™æœ€ä½³æ¨¡å‹")
    print("   â€¢ ä½¿ç”¨æ—©åœé˜²æ­¢è¿‡æ‹Ÿåˆ")
    print("   â€¢ åœ¨è¾ƒå°æ•°æ®é›†ä¸Šå…ˆéªŒè¯é…ç½®")

if __name__ == "__main__":
    print_training_recommendations()