#!/usr/bin/env python3
"""
è¿è¡Œç½®ä¿¡åº¦æ ¡å‡†çš„ä¸»è„šæœ¬
"""
import os
import torch
import json
import numpy as np
from torch.utils.data import DataLoader
from torchvision import transforms

from model import OverLoCKModel
from dataset import OverLoCKDataset
from confidence_calibration import (
    ConfidenceCalibrator, 
    plot_calibration_comparison,
    save_calibration_results,
    calculate_ece,
    calculate_mce
)


def load_model_and_data(checkpoint_path: str = './checkpoints/best_model.pth',
                       data_dir: str = './data',
                       batch_size: int = 32,
                       device: str = 'cuda'):
    """
    åŠ è½½æ¨¡å‹å’Œæ•°æ®
    Args:
        checkpoint_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        data_dir: æ•°æ®ç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡
    Returns:
        model, val_loader, test_loader, class_names
    """
    # ç±»åˆ«åç§°
    class_names = ['æ•‘æŠ¤è½¦', 'æ£•ç†Š', 'æµ·æ˜Ÿ', 'æ¸…çœŸå¯º', 'çŒè±¹', 
                   'è€è™', 'èœœèœ‚', 'é‡å…”', 'é’¢ç¬”', 'é¦™è•‰']
    
    # åˆ›å»ºæ¨¡å‹
    model = OverLoCKModel(class_names=class_names, use_clip=True)
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    
    print(f"âœ… æ¨¡å‹å·²åŠ è½½: {checkpoint_path}")
    
    # æ•°æ®å˜æ¢
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    val_dataset = OverLoCKDataset(
        data_root=data_dir,
        mode='val',
        transform=transform
    )
    
    test_dataset = OverLoCKDataset(
        data_root=data_dir,
        mode='test',
        transform=transform
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=4
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=4
    )
    
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ - éªŒè¯é›†: {len(val_dataset)}, æµ‹è¯•é›†: {len(test_dataset)}")
    
    return model, val_loader, test_loader, class_names


def evaluate_model(model, data_loader, device='cuda', method_name='åŸå§‹'):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½
    Args:
        model: æ¨¡å‹
        data_loader: æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        method_name: æ–¹æ³•åç§°
    Returns:
        results: åŒ…å«æ‰€æœ‰é¢„æµ‹ç»“æœçš„å­—å…¸
    """
    print(f"ğŸ” è¯„ä¼° {method_name} æ¨¡å‹æ€§èƒ½...")
    
    model.eval()
    results = []
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in data_loader:
            images = images.to(device)
            labels = labels.to(device)
            
            main_logits, aux_logits, clip_logits = model(images, use_aux=False)
            probs = torch.softmax(main_logits, dim=1)
            
            # è·å–é¢„æµ‹ç»“æœ
            confidences, predicted = torch.max(probs, 1)
            
            for i in range(len(labels)):
                is_correct = predicted[i].item() == labels[i].item()
                results.append({
                    'confidence': confidences[i].item(),
                    'predicted': predicted[i].item(),
                    'true_label': labels[i].item(),
                    'is_correct': is_correct
                })
                
                if is_correct:
                    correct += 1
                total += 1
    
    accuracy = 100.0 * correct / total
    print(f"âœ… {method_name} å‡†ç¡®ç‡: {accuracy:.2f}%")
    
    return {
        'results': results,
        'accuracy': accuracy,
        'total_samples': total
    }


def evaluate_calibrated_model(model, calibrator, data_loader, method='temperature', device='cuda'):
    """
    è¯„ä¼°æ ¡å‡†åçš„æ¨¡å‹æ€§èƒ½
    Args:
        model: åŸå§‹æ¨¡å‹
        calibrator: æ ¡å‡†å™¨
        data_loader: æ•°æ®åŠ è½½å™¨
        method: æ ¡å‡†æ–¹æ³• ('temperature', 'platt', 'isotonic')
        device: è®¾å¤‡
    Returns:
        results: åŒ…å«æ‰€æœ‰é¢„æµ‹ç»“æœçš„å­—å…¸
    """
    method_names = {
        'temperature': 'æ¸©åº¦ç¼©æ”¾',
        'platt': 'Plattç¼©æ”¾',
        'isotonic': 'ç­‰æ¸—å›å½’'
    }
    
    print(f"ğŸ” è¯„ä¼° {method_names[method]} æ ¡å‡†åæ¨¡å‹æ€§èƒ½...")
    
    model.eval()
    results = []
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in data_loader:
            images = images.to(device)
            labels = labels.to(device)
            
            main_logits, aux_logits, clip_logits = model(images, use_aux=False)
            
            # åº”ç”¨æ ¡å‡†
            if method == 'temperature':
                probs = calibrator.apply_temperature_scaling(main_logits)
            elif method == 'platt':
                original_probs = torch.softmax(main_logits, dim=1)
                probs = calibrator.apply_platt_scaling(original_probs)
            elif method == 'isotonic':
                original_probs = torch.softmax(main_logits, dim=1)
                probs = calibrator.apply_isotonic_regression(original_probs)
            else:
                raise ValueError(f"æœªçŸ¥çš„æ ¡å‡†æ–¹æ³•: {method}")
            
            # è·å–é¢„æµ‹ç»“æœ
            confidences, predicted = torch.max(probs, 1)
            
            for i in range(len(labels)):
                is_correct = predicted[i].item() == labels[i].item()
                results.append({
                    'confidence': confidences[i].item(),
                    'predicted': predicted[i].item(),
                    'true_label': labels[i].item(),
                    'is_correct': is_correct
                })
                
                if is_correct:
                    correct += 1
                total += 1
    
    accuracy = 100.0 * correct / total
    print(f"âœ… {method_names[method]} æ ¡å‡†åå‡†ç¡®ç‡: {accuracy:.2f}%")
    
    return {
        'results': results,
        'accuracy': accuracy,
        'total_samples': total
    }


def print_calibration_metrics(results_dict):
    """
    æ‰“å°æ ¡å‡†æŒ‡æ ‡
    Args:
        results_dict: ç»“æœå­—å…¸
    """
    print("\n" + "="*60)
    print("ğŸ“Š ç½®ä¿¡åº¦æ ¡å‡†ç»“æœæ±‡æ€»")
    print("="*60)
    
    for method_name, results in results_dict.items():
        if method_name == 'original':
            display_name = 'åŸå§‹æ¨¡å‹'
        elif method_name == 'temperature':
            display_name = 'æ¸©åº¦ç¼©æ”¾'
        elif method_name == 'platt':
            display_name = 'Plattç¼©æ”¾'
        elif method_name == 'isotonic':
            display_name = 'ç­‰æ¸—å›å½’'
        else:
            display_name = method_name
        
        print(f"\nğŸ”¹ {display_name}:")
        print(f"   å‡†ç¡®ç‡: {results['accuracy']:.2f}%")
        print(f"   ECE: {results['ece']:.4f}")
        print(f"   MCE: {results['mce']:.4f}")
        print(f"   å¹³å‡ç½®ä¿¡åº¦: {results['avg_confidence']:.4f}")
        print(f"   ç½®ä¿¡åº¦æ ‡å‡†å·®: {results['confidence_std']:.4f}")
    
    print("\n" + "="*60)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç½®ä¿¡åº¦æ ¡å‡†æµç¨‹...")
    
    # è®¾ç½®è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    checkpoint_path = './checkpoints/best_model.pth'
    if not os.path.exists(checkpoint_path):
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {checkpoint_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
        return
    
    # åŠ è½½æ¨¡å‹å’Œæ•°æ®
    try:
        model, val_loader, test_loader, class_names = load_model_and_data(
            checkpoint_path=checkpoint_path,
            device=device
        )
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å’Œæ•°æ®å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºæ ¡å‡†å™¨
    calibrator = ConfidenceCalibrator(model, device)
    
    # 1. è¯„ä¼°åŸå§‹æ¨¡å‹
    print("\n" + "="*50)
    print("ğŸ“Š ç¬¬ä¸€æ­¥: è¯„ä¼°åŸå§‹æ¨¡å‹")
    print("="*50)
    
    original_results = evaluate_model(model, test_loader, device, 'åŸå§‹')
    
    # 2. è¿›è¡Œæ ¡å‡†è®­ç»ƒ
    print("\n" + "="*50)
    print("ğŸ”§ ç¬¬äºŒæ­¥: è®­ç»ƒæ ¡å‡†å™¨")
    print("="*50)
    
    try:
        # æ¸©åº¦ç¼©æ”¾æ ¡å‡†
        optimal_temp = calibrator.calibrate_temperature_scaling(val_loader)
        
        # Plattç¼©æ”¾æ ¡å‡†
        calibrator.calibrate_platt_scaling(val_loader)
        
        # ç­‰æ¸—å›å½’æ ¡å‡†
        calibrator.calibrate_isotonic_regression(val_loader)
        
    except Exception as e:
        print(f"âŒ æ ¡å‡†è®­ç»ƒå¤±è´¥: {e}")
        return
    
    # 3. è¯„ä¼°æ ¡å‡†åçš„æ¨¡å‹
    print("\n" + "="*50)
    print("ğŸ“Š ç¬¬ä¸‰æ­¥: è¯„ä¼°æ ¡å‡†åæ¨¡å‹")
    print("="*50)
    
    calibrated_results = {}
    
    # è¯„ä¼°æ¸©åº¦ç¼©æ”¾
    try:
        temp_results = evaluate_calibrated_model(
            model, calibrator, test_loader, 'temperature', device
        )
        calibrated_results['temperature'] = temp_results
    except Exception as e:
        print(f"âš ï¸  æ¸©åº¦ç¼©æ”¾è¯„ä¼°å¤±è´¥: {e}")
    
    # è¯„ä¼°Plattç¼©æ”¾
    try:
        platt_results = evaluate_calibrated_model(
            model, calibrator, test_loader, 'platt', device
        )
        calibrated_results['platt'] = platt_results
    except Exception as e:
        print(f"âš ï¸  Plattç¼©æ”¾è¯„ä¼°å¤±è´¥: {e}")
    
    # è¯„ä¼°ç­‰æ¸—å›å½’
    try:
        isotonic_results = evaluate_calibrated_model(
            model, calibrator, test_loader, 'isotonic', device
        )
        calibrated_results['isotonic'] = isotonic_results
    except Exception as e:
        print(f"âš ï¸  ç­‰æ¸—å›å½’è¯„ä¼°å¤±è´¥: {e}")
    
    # 4. ä¿å­˜ç»“æœå’Œç”Ÿæˆå¯è§†åŒ–
    print("\n" + "="*50)
    print("ğŸ’¾ ç¬¬å››æ­¥: ä¿å­˜ç»“æœå’Œç”Ÿæˆå¯è§†åŒ–")
    print("="*50)
    
    try:
        # ä¿å­˜æ ¡å‡†ç»“æœ
        results_summary = save_calibration_results(
            original_results, 
            calibrated_results,
            './result/calibration_results.json'
        )
        
        # ç”Ÿæˆå¯¹æ¯”å›¾
        plot_calibration_comparison(
            original_results,
            calibrated_results,
            './result/calibration_comparison.png'
        )
        
        # æ‰“å°ç»“æœæ±‡æ€»
        print_calibration_metrics(results_summary)
        
        print("\nğŸ‰ ç½®ä¿¡åº¦æ ¡å‡†æµç¨‹å®Œæˆï¼")
        print("ğŸ“ ç»“æœæ–‡ä»¶:")
        print("   - æ ¡å‡†å¯¹æ¯”å›¾: ./result/calibration_comparison.png")
        print("   - æ ¡å‡†ç»“æœæ•°æ®: ./result/calibration_results.json")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        return


if __name__ == "__main__":
    main()
