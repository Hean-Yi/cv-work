import os
import torch
import random
import json
import matplotlib.pyplot as plt
import warnings
from torchvision import transforms
from PIL import Image
import numpy as np

from model import OverLoCKModel
from dataset import OverLoCKDataset
from model_visualizer import ModelVisualizer  # å¯¼å…¥æ–°çš„å¯è§†åŒ–æ¨¡å—

def load_trained_model(checkpoint_path, class_names, device='cuda'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    # å°è¯•ä¸åŒçš„æ¨¡å‹å¯¼å…¥
    try:
        from scalable_model import ScalableOverLoCKModel
        from rtx4090_configs import RTX4090OptimalConfig
        
        # ä½¿ç”¨å¯æ‰©å±•æ¨¡å‹
        config = RTX4090OptimalConfig()
        model = ScalableOverLoCKModel(
            class_names=class_names,
            config=config
        )
        print("âœ… ä½¿ç”¨å¯æ‰©å±•æ¨¡å‹")
    except ImportError:
        # å›é€€åˆ°åŸå§‹æ¨¡å‹
        model = OverLoCKModel(
            class_names=class_names,
            use_clip=True
        )
        print("âœ… ä½¿ç”¨åŸå§‹æ¨¡å‹")
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # å¤„ç†ä¸åŒçš„æ£€æŸ¥ç‚¹æ ¼å¼
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    # ç§»åŠ¨åˆ°è®¾å¤‡
    model.to(device)
    model.eval()
    
    print(f"ğŸ“Š æ¨¡å‹å·²åŠ è½½: {checkpoint_path}")
    return model

def run_comprehensive_evaluation(model, dataloader, device='cuda', save_dir='./visualizations'):
    """
    è¿è¡Œç»¼åˆè¯„ä¼°ï¼ŒåŒ…å«æ‰€æœ‰å¯è§†åŒ–åŠŸèƒ½
    """
    print("ğŸš€ å¼€å§‹ç»¼åˆæ¨¡å‹è¯„ä¼°...")
    print("="*60)
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = ModelVisualizer(model, device=device, save_dir=save_dir)
    
    # 1. è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    print("ğŸ“Š 1/3 è®¡ç®—æ¨¡å‹è¯„ä¼°æŒ‡æ ‡...")
    metrics = visualizer.calculate_metrics(dataloader, num_samples=500)
    
    # 2. ERFå¯è§†åŒ–
    print("ğŸ” 2/3 ç”Ÿæˆæœ‰æ•ˆæ„Ÿå—é‡å¯è§†åŒ–...")
    erf_maps = visualizer.visualize_effective_receptive_field(dataloader, num_images=100)
    
    # 3. GradCAMå¯è§†åŒ–
    print("ğŸ¯ 3/3 ç”ŸæˆGradCAMç±»æ¿€æ´»å›¾...")
    
    # è·å–ä¸€æ‰¹æ ·æœ¬ç”¨äºGradCAM
    for images, labels in dataloader:
        # åªå–å‰8ä¸ªæ ·æœ¬è¿›è¡Œå¯è§†åŒ–
        sample_images = images[:8].to(device)
        sample_labels = labels[:8].to(device)
        
        gradcams = visualizer.visualize_gradcam(sample_images, sample_labels)
        break  # åªå¤„ç†ç¬¬ä¸€æ‰¹
    
    print("âœ… ç»¼åˆè¯„ä¼°å®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")
    
    return metrics, erf_maps, gradcams

def inference_with_visualization():
    """æ¨ç†å¹¶è¿›è¡Œå¯è§†åŒ–çš„ä¸»å‡½æ•°"""
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ£€æŸ¥ç‚¹è·¯å¾„
    checkpoint_paths = [
        './checkpoints/rtx4090_optimal_best_model.pth',
        './checkpoints/rtx4090_max_best_model.pth', 
        './checkpoints/best_model.pth'
    ]
    
    checkpoint_path = None
    for path in checkpoint_paths:
        if os.path.exists(path):
            checkpoint_path = path
            break
    
    if checkpoint_path is None:
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶")
        print("ğŸ’¡ è¯·ç¡®ä¿è®­ç»ƒå®Œæˆå¹¶ä¿å­˜äº†æ¨¡å‹")
        return
    
    # æ•°æ®å˜æ¢
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    try:
        # å°è¯•ImageNet-100
        dataset = OverLoCKDataset(
            data_root="./data/imagenet100",
            mode='val',
            transform=transform,
            dataset_type='imagenet100'
        )
        print("âœ… ä½¿ç”¨ImageNet-100éªŒè¯é›†")
    except:
        try:
            # å›é€€åˆ°CIFAR-10
            dataset = OverLoCKDataset(
                data_root="./data",
                mode='test', 
                transform=transform,
                dataset_type='cifar10'
            )
            print("âœ… ä½¿ç”¨CIFAR-10æµ‹è¯•é›†")
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½æ•°æ®é›†: {e}")
            return
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataloader = torch.utils.data.DataLoader(
        dataset, 
        batch_size=16, 
        shuffle=False,
        num_workers=2
    )
    
    print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"  æ ·æœ¬æ•°é‡: {len(dataset)}")
    print(f"  ç±»åˆ«æ•°é‡: {dataset.get_num_classes()}")
    
    # åŠ è½½æ¨¡å‹
    class_names = dataset.get_class_names()
    model = load_trained_model(checkpoint_path, class_names, device)
    
    # è¿è¡Œç»¼åˆè¯„ä¼°
    save_dir = './evaluation_results'
    os.makedirs(save_dir, exist_ok=True)
    
    try:
        metrics, erf_maps, gradcams = run_comprehensive_evaluation(
            model, dataloader, device, save_dir
        )
        
        print("\nğŸ‰ æ¨ç†å’Œå¯è§†åŒ–å®Œæˆ!")
        print(f"ğŸ“ˆ Top-1 å‡†ç¡®ç‡: {metrics.get('top1_accuracy', 'N/A')}")
        print(f"ğŸ“ˆ Top-5 å‡†ç¡®ç‡: {metrics.get('top5_accuracy', 'N/A')}")
        print(f"ğŸš€ ååé‡: {metrics.get('throughput', 'N/A')} imgs/sec")
        print(f"ğŸ”¢ å‚æ•°é‡: {metrics.get('total_params', 'N/A')/1e6:.2f}M")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # è¿è¡Œæ¨ç†å’Œå¯è§†åŒ–
    success = inference_with_visualization()
    
    if success:
        print("âœ… æ¨ç†å’Œå¯è§†åŒ–æˆåŠŸå®Œæˆ!")
    else:
        print("âŒ æ¨ç†å’Œå¯è§†åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")