import os
from typing import List, Tuple
from PIL import Image
import torch
from torch.utils.data import Dataset

class OverLoCKDataset(Dataset):
    """é€šç”¨æ•°æ®é›†è¯»å–ç±»ï¼ˆæ”¯æŒ CIFAR-10 å’Œ ImageNet-100ï¼‰"""
    def __init__(self, data_root: str, mode: str = 'train', transform=None, dataset_type: str = 'auto'):
        """
        Args:
            data_root: æ•°æ®é›†æ ¹ç›®å½•ï¼Œä¾‹å¦‚ "cifar-10-images" æˆ– "data/imagenet100"
            mode: 'train' æˆ– 'test' æˆ– 'val'
            transform: torchvision.transforms å›¾åƒå˜æ¢
            dataset_type: 'cifar10', 'imagenet100', 'auto' (è‡ªåŠ¨æ£€æµ‹)
        """
        super(OverLoCKDataset, self).__init__()
        self.data_root = data_root
        self.mode = mode
        self.transform = transform
        self.dataset_type = dataset_type

        self.samples = []       # List of (image_path, label)
        self.class_names = []   # ç±»åˆ«åç§°åˆ—è¡¨

        # è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†ç±»å‹
        if self.dataset_type == 'auto':
            self.dataset_type = self._detect_dataset_type()
        
        # åŠ è½½æ‰€æœ‰æ ·æœ¬ä¿¡æ¯
        self._load_annotations()

    def _detect_dataset_type(self) -> str:
        """è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†ç±»å‹"""
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å…¸å‹çš„ImageNet-100ç»“æ„
        possible_modes = ['train', 'val', 'test']
        for mode in possible_modes:
            mode_dir = os.path.join(self.data_root, mode)
            if os.path.exists(mode_dir):
                # æ£€æŸ¥ç±»åˆ«æ•°é‡æ¥åˆ¤æ–­æ•°æ®é›†ç±»å‹
                classes = [d for d in os.listdir(mode_dir) 
                          if os.path.isdir(os.path.join(mode_dir, d))]
                if len(classes) >= 90:  # ImageNet-100 æœ‰100ä¸ªç±»åˆ«
                    return 'imagenet100'
                elif len(classes) == 10:  # CIFAR-10 æœ‰10ä¸ªç±»åˆ«
                    return 'cifar10'
        
        # é»˜è®¤è¿”å› cifar10
        return 'cifar10'

    def _check_and_extract_imagenet100(self):
        """æ£€æŸ¥å¹¶è§£å‹ImageNet-100æ•°æ®é›†"""
        import zipfile
        import tarfile
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»è§£å‹
        if os.path.exists(os.path.join(self.data_root, 'train')) and os.path.exists(os.path.join(self.data_root, 'val')):
            return  # å·²ç»è§£å‹ï¼Œæ— éœ€æ“ä½œ
        
        print("ğŸ”„ æ£€æµ‹åˆ°ImageNet-100å‹ç¼©æ–‡ä»¶ï¼Œå¼€å§‹è§£å‹...")
        
        # æŸ¥æ‰¾å‹ç¼©æ–‡ä»¶
        compressed_files = []
        for file in os.listdir(self.data_root):
            if file.startswith('train.X') or file.startswith('val.X'):
                compressed_files.append(os.path.join(self.data_root, file))
        
        if not compressed_files:
            print("âš ï¸ æœªæ‰¾åˆ°ImageNet-100å‹ç¼©æ–‡ä»¶")
            return
        
        # åˆå¹¶å¹¶è§£å‹æ–‡ä»¶ (å‡è®¾æ˜¯åˆ†å·å‹ç¼©)
        try:
            # å°è¯•è§£å‹trainæ–‡ä»¶
            train_files = [f for f in compressed_files if 'train' in f]
            if train_files:
                print("ğŸ“¦ è§£å‹è®­ç»ƒé›†...")
                # å¦‚æœæ˜¯zipåˆ†å·ï¼Œéœ€è¦å…ˆåˆå¹¶
                train_files.sort()  # ç¡®ä¿é¡ºåºæ­£ç¡®
                
                # å°è¯•ç›´æ¥è§£å‹ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼ˆé€šå¸¸åŒ…å«æ‰€æœ‰æ•°æ®ï¼‰
                try:
                    with zipfile.ZipFile(train_files[0], 'r') as zip_ref:
                        zip_ref.extractall(self.data_root)
                        print("âœ… è®­ç»ƒé›†è§£å‹å®Œæˆ")
                except:
                    # å¦‚æœå¤±è´¥ï¼Œå°è¯•taræ ¼å¼
                    try:
                        with tarfile.open(train_files[0], 'r') as tar_ref:
                            tar_ref.extractall(self.data_root)
                            print("âœ… è®­ç»ƒé›†è§£å‹å®Œæˆ")
                    except:
                        print("âŒ è®­ç»ƒé›†è§£å‹å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è§£å‹")
            
            # å°è¯•è§£å‹valæ–‡ä»¶
            val_files = [f for f in compressed_files if 'val' in f]
            if val_files:
                print("ğŸ“¦ è§£å‹éªŒè¯é›†...")
                try:
                    with zipfile.ZipFile(val_files[0], 'r') as zip_ref:
                        zip_ref.extractall(self.data_root)
                        print("âœ… éªŒè¯é›†è§£å‹å®Œæˆ")
                except:
                    try:
                        with tarfile.open(val_files[0], 'r') as tar_ref:
                            tar_ref.extractall(self.data_root)
                            print("âœ… éªŒè¯é›†è§£å‹å®Œæˆ")
                    except:
                        print("âŒ éªŒè¯é›†è§£å‹å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è§£å‹")
                        
        except Exception as e:
            print(f"âš ï¸ è§£å‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            print("ğŸ’¡ è¯·æ‰‹åŠ¨è§£å‹ImageNet-100æ•°æ®é›†æ–‡ä»¶")

    def _handle_imagenet100_structure(self):
        """å¤„ç†ImageNet-100çš„ç‰¹æ®Šç›®å½•ç»“æ„ (train.X1, train.X2, ..., val.X)"""
        import shutil
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»åˆå¹¶
        train_dir = os.path.join(self.data_root, 'train')
        val_dir = os.path.join(self.data_root, 'val')
        
        if os.path.exists(train_dir) and os.path.exists(val_dir):
            return  # å·²ç»åˆå¹¶ï¼Œæ— éœ€æ“ä½œ
        
        print("ğŸ”„ æ£€æµ‹åˆ°ImageNet-100åˆ†å—ç›®å½•ç»“æ„ï¼Œæ­£åœ¨åˆå¹¶...")
        
        # åˆå¹¶è®­ç»ƒé›† (train.X1, train.X2, train.X3, train.X4)
        train_parts = ['train.X1', 'train.X2', 'train.X3', 'train.X4']
        train_parts = [os.path.join(self.data_root, part) for part in train_parts if os.path.exists(os.path.join(self.data_root, part))]
        
        if train_parts and not os.path.exists(train_dir):
            print(f"ğŸ“¦ åˆå¹¶è®­ç»ƒé›† ({len(train_parts)} ä¸ªåˆ†å—)...")
            os.makedirs(train_dir, exist_ok=True)
            
            # æ”¶é›†æ‰€æœ‰ç±»åˆ«
            all_classes = set()
            for part_dir in train_parts:
                if os.path.isdir(part_dir):
                    classes = [d for d in os.listdir(part_dir) if os.path.isdir(os.path.join(part_dir, d))]
                    all_classes.update(classes)
            
            print(f"ğŸ“‚ å‘ç° {len(all_classes)} ä¸ªç±»åˆ«")
            
            # ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºç›®å½•å¹¶åˆå¹¶å›¾ç‰‡
            for class_name in sorted(all_classes):
                class_dir = os.path.join(train_dir, class_name)
                os.makedirs(class_dir, exist_ok=True)
                
                # ä»å„ä¸ªåˆ†å—å¤åˆ¶è¯¥ç±»åˆ«çš„å›¾ç‰‡
                total_images = 0
                for part_dir in train_parts:
                    part_class_dir = os.path.join(part_dir, class_name)
                    if os.path.exists(part_class_dir):
                        images = [f for f in os.listdir(part_class_dir) 
                                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                        for img in images:
                            src = os.path.join(part_class_dir, img)
                            dst = os.path.join(class_dir, img)
                            if not os.path.exists(dst):  # é¿å…é‡å¤å¤åˆ¶
                                shutil.copy2(src, dst)
                                total_images += 1
                
                if total_images > 0:
                    print(f"  âœ… {class_name}: {total_images} å¼ å›¾ç‰‡")
            
            print("âœ… è®­ç»ƒé›†åˆå¹¶å®Œæˆ")
        
        # å¤„ç†éªŒè¯é›† (val.X)
        val_part = os.path.join(self.data_root, 'val.X')
        if os.path.exists(val_part) and os.path.isdir(val_part) and not os.path.exists(val_dir):
            print("ğŸ“¦ å¤„ç†éªŒè¯é›†...")
            
            # ç›´æ¥é‡å‘½åæˆ–å¤åˆ¶val.Xåˆ°val
            try:
                shutil.move(val_part, val_dir)
                print("âœ… éªŒè¯é›†å¤„ç†å®Œæˆ (é‡å‘½å)")
            except:
                # å¦‚æœé‡å‘½åå¤±è´¥ï¼Œå°è¯•å¤åˆ¶
                shutil.copytree(val_part, val_dir)
                print("âœ… éªŒè¯é›†å¤„ç†å®Œæˆ (å¤åˆ¶)")
        
        # éªŒè¯ç»“æœ
        if os.path.exists(train_dir):
            train_classes = len([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])
            print(f"ğŸ“Š è®­ç»ƒé›†: {train_classes} ä¸ªç±»åˆ«")
        
        if os.path.exists(val_dir):
            val_classes = len([d for d in os.listdir(val_dir) if os.path.isdir(os.path.join(val_dir, d))])
            print(f"ğŸ“Š éªŒè¯é›†: {val_classes} ä¸ªç±»åˆ«")

    def _load_annotations(self):
        """æ‰«ææ–‡ä»¶å¤¹ï¼Œå°†æ¯ä¸ªå›¾ç‰‡è·¯å¾„å’Œæ ‡ç­¾å­˜å…¥ samples"""
        # æ£€æŸ¥ImageNet-100çš„ç‰¹æ®Šç›®å½•ç»“æ„
        if self.dataset_type == 'imagenet100':
            self._handle_imagenet100_structure()
        
        # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©åˆé€‚çš„æ¨¡å¼ç›®å½•
        if self.dataset_type == 'imagenet100':
            # ImageNet-100 ä½¿ç”¨åˆå¹¶åçš„ç›®å½•ç»“æ„
            if self.mode == 'test' or self.mode == 'val':
                mode_name = 'val'
            else:
                mode_name = 'train'
        else:
            # CIFAR-10 æ”¯æŒ train/test
            mode_name = self.mode
            
        mode_dir = os.path.join(self.data_root, mode_name)
        
        if not os.path.exists(mode_dir):
            raise FileNotFoundError(f"æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {mode_dir}")
        
        self.class_names = sorted([d for d in os.listdir(mode_dir) 
                                  if os.path.isdir(os.path.join(mode_dir, d))])  # åªè·å–ç›®å½•

        # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©å›¾åƒæ–‡ä»¶æ‰©å±•å
        if self.dataset_type == 'imagenet100':
            valid_extensions = [".JPEG", ".jpg", ".jpeg", ".png", ".PNG"]
        else:
            valid_extensions = [".JPEG", ".jpg", ".jpeg", ".png", ".PNG"]

        # éå†æ¯ä¸ªç±»åˆ«æ–‡ä»¶å¤¹
        for class_idx, class_name in enumerate(self.class_names):
            class_dir = os.path.join(mode_dir, class_name)
            if not os.path.isdir(class_dir):
                continue
                
            for fname in os.listdir(class_dir):
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                if any(fname.endswith(ext) for ext in valid_extensions):
                    self.samples.append((os.path.join(class_dir, fname), class_idx))

    def __len__(self) -> int:
        """è¿”å›æ•°æ®é›†æ ·æœ¬æ•°é‡"""
        return len(self.samples)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:
        """
        è¿”å›ä¸€ä¸ªæ ·æœ¬
        Returns:
            image: [C, H, W] çš„ torch.Tensor
            label: ç±»åˆ«ç´¢å¼• int
        """
        img_path, label = self.samples[idx]
        
        try:
            image = Image.open(img_path).convert("RGB")  # æ‰“å¼€å›¾åƒå¹¶è½¬æ¢æˆ RGB
        except Exception as e:
            print(f"Warning: Failed to load image {img_path}: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„é»‘è‰²å›¾åƒ
            image = Image.new('RGB', (224, 224), (0, 0, 0))

        # åº”ç”¨å˜æ¢ï¼ˆå¦‚ ToTensorã€å½’ä¸€åŒ–ï¼‰
        if self.transform:
            image = self.transform(image)

        return image, label

    def get_class_names(self) -> List[str]:
        """è¿”å›ç±»åˆ«åç§°åˆ—è¡¨"""
        return self.class_names

    def get_num_classes(self) -> int:
        """è¿”å›ç±»åˆ«æ•°é‡"""
        return len(self.class_names)
    
    def get_dataset_info(self) -> dict:
        """è¿”å›æ•°æ®é›†ä¿¡æ¯"""
        return {
            'dataset_type': self.dataset_type,
            'mode': self.mode,
            'num_classes': self.get_num_classes(),
            'num_samples': len(self.samples),
            'class_names': self.class_names[:10],  # åªæ˜¾ç¤ºå‰10ä¸ªç±»åˆ«å
            'data_root': self.data_root
        }
