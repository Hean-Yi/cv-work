import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from typing import Optional, Tuple
from tqdm import tqdm
from confidence_calibration import ConfidenceCalibrator


class OverLoCKTrainer:
    """OverLoCK è®­ç»ƒå™¨ç±»"""
    def __init__(self,
                 model: nn.Module,
                 train_dataset: Dataset,
                 val_dataset: Optional[Dataset] = None,
                 batch_size: int = 32,
                 learning_rate: float = 1e-4,
                 num_epochs: int = 100,
                 device: str = 'cuda',
                 save_dir: str = './checkpoints',
                 clip_loss_weight: float = 0.1,
                 multi_gpu: bool = False):
        """
        Args:
            model: OverLoCKæ¨¡å‹
            train_dataset: è®­ç»ƒæ•°æ®é›†
            val_dataset: éªŒè¯æ•°æ®é›†
            batch_size: æ‰¹æ¬¡å¤§å°
            learning_rate: å­¦ä¹ ç‡
            num_epochs: è®­ç»ƒè½®æ•°
            device: è®¾å¤‡
            save_dir: æ¨¡å‹ä¿å­˜ç›®å½•
            clip_loss_weight: CLIPæŸå¤±æƒé‡
            multi_gpu: æ˜¯å¦ä½¿ç”¨å¤šGPUè®­ç»ƒ
        """
        self.train_dataset = train_dataset
        self.val_dataset = val_dataset
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.save_dir = save_dir
        self.clip_loss_weight = clip_loss_weight
        self.multi_gpu = multi_gpu

        # å¤šGPUè®¾ç½®
        if multi_gpu and torch.cuda.device_count() > 1:
            print(f"ğŸš€ Detected {torch.cuda.device_count()} GPUs, enabling multi-GPU parallel training")
            model = nn.DataParallel(model)
            # åŒGPUæ—¶æœ‰æ•ˆbatch_sizeç¿»å€
            effective_batch_size = batch_size * torch.cuda.device_count()
            print(f"ğŸ“Š Multi-GPU training: effective_batch_size={effective_batch_size} (per GPU: {batch_size})")
        elif multi_gpu:
            print("âš ï¸ Requested multi-GPU training but only 1 GPU detected, using single GPU training")
            effective_batch_size = batch_size
        else:
            effective_batch_size = batch_size
            
        self.effective_batch_size = effective_batch_size
        self.model = model
        
        # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡
        self.model.to(self.device)

        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)

        # æ•°æ®åŠ è½½å™¨ - é’ˆå¯¹å¤šGPUä¼˜åŒ–
        num_workers = 8 if multi_gpu else 4  # åŒGPUæ—¶å¢åŠ workers
        
        self.train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=True,
            persistent_workers=True,  # ä¿æŒworkerè¿›ç¨‹å­˜æ´»
            prefetch_factor=2         # é¢„å–æ•°æ®
        )

        if val_dataset:
            self.val_loader = DataLoader(
                val_dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=num_workers,
                pin_memory=True,
                persistent_workers=True,
                prefetch_factor=2
            )
        else:
            self.val_loader = None

        # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•° - ä½¿ç”¨è®ºæ–‡ä¸­çš„è®¾ç½®
        self.optimizer = torch.optim.AdamW(
            model.parameters(), 
            lr=learning_rate,  # ä½¿ç”¨ä¼ å…¥çš„å­¦ä¹ ç‡ï¼ˆåº”è¯¥æ˜¯4e-3ï¼‰
            weight_decay=0.05,  # è®ºæ–‡ä¸­çš„æƒé‡è¡°å‡
            betas=(0.9, 0.999)
        )
        
        # ä½¿ç”¨å¸¦é¢„çƒ­çš„ä½™å¼¦é€€ç«è°ƒåº¦å™¨
        warmup_epochs = max(1, num_epochs // 10)  # é¢„çƒ­è½®æ•°ä¸ºæ€»è½®æ•°çš„10%
        # ç¡®ä¿T_0è‡³å°‘ä¸º1ï¼Œé¿å…å­¦ä¹ ç‡è°ƒåº¦å™¨é”™è¯¯
        T_0 = max(1, num_epochs - warmup_epochs)
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer, 
            T_0=T_0,
            T_mult=1,
            eta_min=learning_rate * 0.01  # æœ€å°å­¦ä¹ ç‡ä¸ºåˆå§‹å­¦ä¹ ç‡çš„1%
        )
        
        # æ·»åŠ æ ‡ç­¾å¹³æ»‘
        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

        # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡
        self.model.to(self.device)

        # ä¿®å¤inplaceæ“ä½œ
        self._disable_inplace_operations()

        # è®­ç»ƒå†å²è®°å½•
        self.history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': []
        }

    def _disable_inplace_operations(self):
        """ç¦ç”¨æ¨¡å‹ä¸­çš„æ‰€æœ‰inplaceæ“ä½œ"""
        inplace_found = []
        for name, module in self.model.named_modules():
            if hasattr(module, 'inplace') and module.inplace:
                module.inplace = False
                inplace_found.append(name)
        
        if inplace_found:
            print(f"Disabled inplace operations for modules: {inplace_found}")
        else:
            print("No inplace operations found, model is normal")

    def train_epoch(self) -> Tuple[float, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        import time
        
        # å¯ç”¨å¼‚å¸¸æ£€æµ‹
        torch.autograd.set_detect_anomaly(True)
        
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        # æ€§èƒ½ç›‘æ§
        epoch_start_time = time.time()
        batch_times = []

        pbar = tqdm(self.train_loader, desc='Training')
        for batch_idx, (images, labels) in enumerate(pbar):
            batch_start_time = time.time()
            
            try:
                images = images.to(self.device, non_blocking=True)
                labels = labels.to(self.device, non_blocking=True)

                # å‰å‘ä¼ æ’­
                main_logits, aux_logits, clip_logits = self.model(images, use_aux=True)

                # è®¡ç®—æŸå¤±
                loss_cls = self.criterion(main_logits, labels)
                loss = loss_cls

                # æ·»åŠ è¾…åŠ©æŸå¤±(å¦‚æœæœ‰)
                if aux_logits is not None:
                    loss_aux = self.criterion(aux_logits, labels)
                    loss = loss + 0.3 * loss_aux  # è¾…åŠ©æŸå¤±æƒé‡

                # æ·»åŠ CLIPæŸå¤±(å¦‚æœæœ‰)
                if clip_logits is not None:
                    loss_clip = self.criterion(clip_logits, labels)
                    loss = loss + self.clip_loss_weight * loss_clip

                # åå‘ä¼ æ’­
                self.optimizer.zero_grad()
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                self.optimizer.step()

                # ç»Ÿè®¡
                batch_end_time = time.time()
                batch_time = batch_end_time - batch_start_time
                batch_times.append(batch_time)
                
                # è®¡ç®—ååé‡ï¼ˆæ¯ç§’å¤„ç†çš„æ ·æœ¬æ•°ï¼‰
                throughput = self.effective_batch_size / batch_time
                total_loss += loss.item()
                _, predicted = torch.max(main_logits.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

                # æ›´æ–°è¿›åº¦æ¡ - æ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
                if batch_idx % 10 == 0:  # æ¯10ä¸ªbatchæ˜¾ç¤ºä¸€æ¬¡æ€§èƒ½
                    avg_batch_time = sum(batch_times[-10:]) / len(batch_times[-10:])
                    avg_throughput = self.effective_batch_size / avg_batch_time
                    pbar.set_postfix({
                        'Loss': f'{loss.item():.4f}',
                        'Acc': f'{100.*correct/total:.2f}%',
                        'Throughput': f'{avg_throughput:.1f} imgs/s',
                        'Time/batch': f'{avg_batch_time:.3f}s'
                    })
                
            except Exception as e:
                print(f"Error during training: {e}")
                print("Suggest checking model structure")
                raise e

        # å…³é—­å¼‚å¸¸æ£€æµ‹
        torch.autograd.set_detect_anomaly(False)
        
        # Epochæ€§èƒ½ç»Ÿè®¡
        epoch_end_time = time.time()
        epoch_duration = epoch_end_time - epoch_start_time
        avg_batch_time = sum(batch_times) / len(batch_times)
        total_samples = total
        epoch_throughput = total_samples / epoch_duration
        
        print(f"\nğŸ“Š Epoch Performance:")
        print(f"   Total time: {epoch_duration:.2f}s")
        print(f"   Avg batch time: {avg_batch_time:.3f}s") 
        print(f"   Epoch throughput: {epoch_throughput:.1f} imgs/s")
        print(f"   Total samples processed: {total_samples}")
        
        avg_loss = total_loss / len(self.train_loader)
        avg_acc = 100. * correct / total

        return avg_loss, avg_acc

    def validate(self) -> Tuple[float, float]:
        """éªŒè¯æ¨¡å‹"""
        if self.val_loader is None:
            return 0.0, 0.0

        self.model.eval()
        total_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            pbar = tqdm(self.val_loader, desc='Validation')
            for batch_idx, (images, labels) in enumerate(pbar):
                images = images.to(self.device)
                labels = labels.to(self.device)

                # å‰å‘ä¼ æ’­
                main_logits, aux_logits, clip_logits = self.model(images, use_aux=False)

                # è®¡ç®—æŸå¤±
                loss = self.criterion(main_logits, labels)

                # ç»Ÿè®¡
                total_loss += loss.item()
                _, predicted = torch.max(main_logits.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

                pbar.set_postfix({
                    'loss': f'{loss.item():.4f}',
                    'acc': f'{100.*correct/total:.2f}%'
                })

        avg_loss = total_loss / len(self.val_loader)
        avg_acc = 100. * correct / total

        return avg_loss, avg_acc

    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print(f"Starting training on device: {self.device}")
        print(f"Total epochs: {self.num_epochs}")
        print(f"Batch size: {self.batch_size}")
        print(f"Learning rate: {self.learning_rate}")

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœ€ä½³æ¨¡å‹ï¼Œå¦‚æœå­˜åœ¨åˆ™åŠ è½½å…¶éªŒè¯å‡†ç¡®ç‡
        best_model_path = os.path.join(self.save_dir, 'best_model.pth')
        best_val_acc = 0.0
        
        if os.path.exists(best_model_path):
            try:
                checkpoint = torch.load(best_model_path, map_location=self.device)
                best_val_acc = checkpoint.get('val_acc', 0.0)
                print(f"ğŸ” Found existing best model, validation accuracy: {best_val_acc:.2f}%")
                print(f"ğŸ“Š New training will only save as best model when validation accuracy exceeds {best_val_acc:.2f}%")
            except Exception as e:
                print(f"âš ï¸ Unable to load existing best model: {e}")
                print("ğŸ”„ Starting from validation accuracy 0.0%")
                best_val_acc = 0.0
        else:
            print("ğŸ†• No existing best model found, starting from validation accuracy 0.0%")

        for epoch in range(self.num_epochs):
            print(f"\nEpoch [{epoch+1}/{self.num_epochs}]")

            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch()
            self.history['train_loss'].append(train_loss)
            self.history['train_acc'].append(train_acc)

            # éªŒè¯
            val_loss, val_acc = self.validate()
            self.history['val_loss'].append(val_loss)
            self.history['val_acc'].append(val_acc)

            # è°ƒæ•´å­¦ä¹ ç‡
            self.scheduler.step()

            # æ‰“å°ç»“æœ
            print(f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
            print(f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                self.save_checkpoint(epoch, val_acc, is_best=True)

            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % 10 == 0:
                self.save_checkpoint(epoch, val_acc, is_best=False)

        # è®­ç»ƒå®Œæˆåè¿è¡Œå¯è§†åŒ–
        print("\n" + "="*60)
        print("ğŸ¨ Training completed! Starting visualization generation...")
        print("="*60)
        
        try:
            self.run_post_training_visualization()
        except Exception as e:
            print(f"âš ï¸ Visualization generation failed: {e}")
            print("ğŸ’¡ You can manually run later: python inference.py")

    def run_post_training_visualization(self):
        """è®­ç»ƒå®Œæˆåè¿è¡Œå¯è§†åŒ–"""
        try:
            from model_visualizer import ModelVisualizer
            
            # åˆ›å»ºå¯è§†åŒ–å™¨
            visualizer = ModelVisualizer(self.model, device=self.device, save_dir='./visualizations')
            
            print("ğŸ“Š 1/3 Computing model evaluation metrics...")
            # ä½¿ç”¨éªŒè¯é›†è¿›è¡Œè¯„ä¼°
            if self.val_loader is not None:
                metrics = visualizer.calculate_metrics(self.val_loader, num_samples=200)
            else:
                metrics = visualizer.calculate_metrics(self.train_loader, num_samples=200)
            
            print("ğŸ” 2/3 Generating Effective Receptive Field visualization...")
            # ERFå¯è§†åŒ–
            if self.val_loader is not None:
                erf_maps = visualizer.visualize_effective_receptive_field(self.val_loader, num_images=50)
            else:
                erf_maps = visualizer.visualize_effective_receptive_field(self.train_loader, num_images=50)
            
            print("ğŸ¯ 3/3 Generating GradCAM class activation maps...")
            # GradCAMå¯è§†åŒ–
            dataloader = self.val_loader if self.val_loader is not None else self.train_loader
            for images, labels in dataloader:
                sample_images = images[:4].to(self.device)  # åªå–4ä¸ªæ ·æœ¬
                sample_labels = labels[:4].to(self.device)
                gradcams = visualizer.visualize_gradcam(sample_images, sample_labels)
                break
            
            print("âœ… Visualization completed! Results saved in ./visualizations/ directory")
            print(f"ğŸ“ˆ Final validation accuracy: {metrics.get('top1_accuracy', 'N/A')}")
            
        except ImportError:
            print("âš ï¸ Visualization module not found, please ensure model_visualizer.py is uploaded")
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    def save_checkpoint(self, epoch: int, val_acc: float, is_best: bool = False):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'val_acc': val_acc,
            'history': self.history
        }

        if is_best:
            path = os.path.join(self.save_dir, 'best_model.pth')
        else:
            path = os.path.join(self.save_dir, f'checkpoint_epoch_{epoch+1}.pth')

        torch.save(checkpoint, path)
        print(f"Model saved to {path}")

    def load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        self.history = checkpoint['history']
        
        # é‡æ–°ä¿®å¤inplaceæ“ä½œ
        self._disable_inplace_operations()
        
        print(f"Model loaded from {checkpoint_path}")
        return checkpoint['epoch'], checkpoint['val_acc']
    
    def calibrate_confidence(self, test_dataset: Optional[Dataset] = None, 
                           enable_calibration: bool = True):
        """
        è®­ç»ƒå®Œæˆåè¿›è¡Œç½®ä¿¡åº¦æ ¡å‡†
        Args:
            test_dataset: æµ‹è¯•æ•°æ®é›†ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨éªŒè¯é›†
            enable_calibration: æ˜¯å¦å¯ç”¨æ ¡å‡†åŠŸèƒ½
        """
        if not enable_calibration:
            print("âš ï¸  ç½®ä¿¡åº¦æ ¡å‡†åŠŸèƒ½å·²ç¦ç”¨")
            return
            
        if self.val_loader is None:
            print("âš ï¸  æ²¡æœ‰éªŒè¯é›†ï¼Œæ— æ³•è¿›è¡Œç½®ä¿¡åº¦æ ¡å‡†")
            return
        
        print("\n" + "="*60)
        print("ğŸ”§ å¼€å§‹ç½®ä¿¡åº¦æ ¡å‡†...")
        print("="*60)
        
        # åˆ›å»ºæ ¡å‡†å™¨
        calibrator = ConfidenceCalibrator(self.model, str(self.device))
        
        try:
            # ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæ ¡å‡†è®­ç»ƒ
            print("ğŸ“Š ä½¿ç”¨éªŒè¯é›†è®­ç»ƒæ ¡å‡†å™¨...")
            
            # æ¸©åº¦ç¼©æ”¾æ ¡å‡†
            optimal_temp = calibrator.calibrate_temperature_scaling(self.val_loader)
            
            # Plattç¼©æ”¾æ ¡å‡†
            calibrator.calibrate_platt_scaling(self.val_loader)
            
            # ç­‰æ¸—å›å½’æ ¡å‡†
            calibrator.calibrate_isotonic_regression(self.val_loader)
            
            # ä¿å­˜æ ¡å‡†å™¨
            calibrator_path = os.path.join(self.save_dir, 'confidence_calibrator.pth')
            torch.save({
                'temperature_scaler': calibrator.temperature_scaler.state_dict() if calibrator.temperature_scaler else None,
                'platt_scalers': calibrator.platt_scalers,
                'isotonic_scalers': calibrator.isotonic_scalers,
                'class_names': calibrator.class_names,
                'optimal_temperature': optimal_temp
            }, calibrator_path)
            
            print(f"âœ… ç½®ä¿¡åº¦æ ¡å‡†å™¨å·²ä¿å­˜: {calibrator_path}")
            
            # å¦‚æœæœ‰æµ‹è¯•é›†ï¼Œè¿›è¡Œæ ¡å‡†æ•ˆæœè¯„ä¼°
            if test_dataset is not None:
                print("ğŸ“ˆ è¯„ä¼°æ ¡å‡†æ•ˆæœ...")
                
                test_loader = DataLoader(
                    test_dataset,
                    batch_size=self.batch_size,
                    shuffle=False,
                    num_workers=4,
                    pin_memory=True
                )
                
                # è¯„ä¼°åŸå§‹æ¨¡å‹
                original_results = self._evaluate_model_confidence(test_loader, "åŸå§‹æ¨¡å‹")
                
                # è¯„ä¼°æ ¡å‡†åçš„æ¨¡å‹
                calibrated_results = {}
                
                # æ¸©åº¦ç¼©æ”¾
                temp_results = self._evaluate_calibrated_model_confidence(
                    test_loader, calibrator, 'temperature', "æ¸©åº¦ç¼©æ”¾"
                )
                if temp_results:
                    calibrated_results['temperature'] = temp_results
                
                # Plattç¼©æ”¾
                platt_results = self._evaluate_calibrated_model_confidence(
                    test_loader, calibrator, 'platt', "Plattç¼©æ”¾"
                )
                if platt_results:
                    calibrated_results['platt'] = platt_results
                
                # ç­‰æ¸—å›å½’
                isotonic_results = self._evaluate_calibrated_model_confidence(
                    test_loader, calibrator, 'isotonic', "ç­‰æ¸—å›å½’"
                )
                if isotonic_results:
                    calibrated_results['isotonic'] = isotonic_results
                
                # ä¿å­˜å’Œå¯è§†åŒ–ç»“æœ
                if calibrated_results:
                    from confidence_calibration import (
                        save_calibration_results, 
                        plot_calibration_comparison
                    )
                    
                    # ä¿å­˜ç»“æœ
                    results_summary = save_calibration_results(
                        original_results,
                        calibrated_results,
                        './result/training_calibration_results.json'
                    )
                    
                    # ç”Ÿæˆå¯è§†åŒ–
                    plot_calibration_comparison(
                        original_results,
                        calibrated_results,
                        './result/training_calibration_comparison.png'
                    )
                    
                    print("âœ… æ ¡å‡†ç»“æœå·²ä¿å­˜:")
                    print("   - æ•°æ®: ./result/training_calibration_results.json")
                    print("   - å›¾è¡¨: ./result/training_calibration_comparison.png")
            
            print("ğŸ‰ ç½®ä¿¡åº¦æ ¡å‡†å®Œæˆï¼")
            
        except Exception as e:
            print(f"âŒ ç½®ä¿¡åº¦æ ¡å‡†å¤±è´¥: {e}")
            print("ç»§ç»­æ­£å¸¸è®­ç»ƒæµç¨‹...")
    
    def _evaluate_model_confidence(self, data_loader, method_name="æ¨¡å‹"):
        """è¯„ä¼°æ¨¡å‹çš„ç½®ä¿¡åº¦æ€§èƒ½"""
        self.model.eval()
        results = []
        correct = 0
        total = 0
        
        with torch.no_grad():
            for images, labels in data_loader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                main_logits, _, _ = self.model(images)
                probs = torch.softmax(main_logits, dim=1)
                confidences, predicted = torch.max(probs, 1)
                
                for i in range(len(labels)):
                    is_correct = predicted[i].item() == labels[i].item()
                    results.append({
                        'confidence': confidences[i].item(),
                        'predicted': predicted[i].item(),
                        'true_label': labels[i].item(),
                        'is_correct': is_correct
                    })
                    
                    if is_correct:
                        correct += 1
                    total += 1
        
        accuracy = 100.0 * correct / total
        print(f"âœ… {method_name} å‡†ç¡®ç‡: {accuracy:.2f}%")
        
        return {
            'results': results,
            'accuracy': accuracy,
            'total_samples': total
        }
    
    def _evaluate_calibrated_model_confidence(self, data_loader, calibrator, method, method_name):
        """è¯„ä¼°æ ¡å‡†åæ¨¡å‹çš„ç½®ä¿¡åº¦æ€§èƒ½"""
        try:
            self.model.eval()
            results = []
            correct = 0
            total = 0
            
            with torch.no_grad():
                for images, labels in data_loader:
                    images = images.to(self.device)
                    labels = labels.to(self.device)
                    
                    main_logits, _, _ = self.model(images)
                    
                    # åº”ç”¨æ ¡å‡†
                    if method == 'temperature':
                        probs = calibrator.apply_temperature_scaling(main_logits)
                    elif method == 'platt':
                        original_probs = torch.softmax(main_logits, dim=1)
                        probs = calibrator.apply_platt_scaling(original_probs)
                    elif method == 'isotonic':
                        original_probs = torch.softmax(main_logits, dim=1)
                        probs = calibrator.apply_isotonic_regression(original_probs)
                    else:
                        continue
                    
                    confidences, predicted = torch.max(probs, 1)
                    
                    for i in range(len(labels)):
                        is_correct = predicted[i].item() == labels[i].item()
                        results.append({
                            'confidence': confidences[i].item(),
                            'predicted': predicted[i].item(),
                            'true_label': labels[i].item(),
                            'is_correct': is_correct
                        })
                        
                        if is_correct:
                            correct += 1
                        total += 1
            
            accuracy = 100.0 * correct / total
            print(f"âœ… {method_name} æ ¡å‡†åå‡†ç¡®ç‡: {accuracy:.2f}%")
            
            return {
                'results': results,
                'accuracy': accuracy,
                'total_samples': total
            }
            
        except Exception as e:
            print(f"âš ï¸  {method_name} è¯„ä¼°å¤±è´¥: {e}")
            return None
