#!/usr/bin/env python3
"""
ç½®ä¿¡åº¦æ ¡å‡†æ¨¡å—
å®ç°æ¸©åº¦ç¼©æ”¾ã€Plattç¼©æ”¾ç­‰æ ¡å‡†æ–¹æ³•
"""
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from sklearn.isotonic import IsotonicRegression
from sklearn.linear_model import LogisticRegression
from scipy.optimize import minimize_scalar
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
import json
from typing import Tuple, List, Dict, Optional
from torch.utils.data import DataLoader


class TemperatureScaling(nn.Module):
    """
    æ¸©åº¦ç¼©æ”¾æ ¡å‡†æ–¹æ³•
    é€šè¿‡å­¦ä¹ ä¸€ä¸ªæ¸©åº¦å‚æ•°æ¥æ ¡å‡†ç½®ä¿¡åº¦
    """
    def __init__(self, temperature: float = 1.0):
        super(TemperatureScaling, self).__init__()
        self.temperature = nn.Parameter(torch.ones(1) * temperature)
    
    def forward(self, logits: torch.Tensor) -> torch.Tensor:
        """
        åº”ç”¨æ¸©åº¦ç¼©æ”¾
        Args:
            logits: æ¨¡å‹åŸå§‹è¾“å‡º [batch_size, num_classes]
        Returns:
            æ ¡å‡†åçš„æ¦‚ç‡åˆ†å¸ƒ [batch_size, num_classes]
        """
        return torch.softmax(logits / self.temperature, dim=1)
    
    def fit(self, logits: torch.Tensor, labels: torch.Tensor, 
            lr: float = 0.01, max_iter: int = 50) -> float:
        """
        è®­ç»ƒæ¸©åº¦å‚æ•°
        Args:
            logits: éªŒè¯é›†çš„æ¨¡å‹è¾“å‡º
            labels: éªŒè¯é›†çš„çœŸå®æ ‡ç­¾
            lr: å­¦ä¹ ç‡
            max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•°
        Returns:
            æœ€ä¼˜æ¸©åº¦å€¼
        """
        # ç¡®ä¿æ‰€æœ‰å¼ é‡åœ¨åŒä¸€è®¾å¤‡ä¸Š
        device = logits.device
        self.temperature = self.temperature.to(device)
        labels = labels.to(device)
        
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.LBFGS([self.temperature], lr=lr, max_iter=max_iter)
        
        def eval_loss():
            optimizer.zero_grad()
            loss = criterion(logits / self.temperature, labels)
            loss.backward()
            return loss
        
        optimizer.step(eval_loss)
        return self.temperature.item()


class PlattScaling:
    """
    Plattç¼©æ”¾æ ¡å‡†æ–¹æ³•
    ä½¿ç”¨é€»è¾‘å›å½’æ¥æ ¡å‡†ç½®ä¿¡åº¦
    """
    def __init__(self):
        self.calibrator = LogisticRegression()
    
    def fit(self, confidences: np.ndarray, labels: np.ndarray):
        """
        è®­ç»ƒPlattç¼©æ”¾å‚æ•°
        Args:
            confidences: åŸå§‹ç½®ä¿¡åº¦ [n_samples]
            labels: äºŒå…ƒæ ‡ç­¾ (0æˆ–1) [n_samples]
        """
        confidences = confidences.reshape(-1, 1)
        self.calibrator.fit(confidences, labels)
    
    def predict_proba(self, confidences: np.ndarray) -> np.ndarray:
        """
        é¢„æµ‹æ ¡å‡†åçš„æ¦‚ç‡
        Args:
            confidences: åŸå§‹ç½®ä¿¡åº¦ [n_samples]
        Returns:
            æ ¡å‡†åçš„æ¦‚ç‡ [n_samples]
        """
        confidences = confidences.reshape(-1, 1)
        return self.calibrator.predict_proba(confidences)[:, 1]


class IsotonicCalibration:
    """
    ç­‰æ¸—å›å½’æ ¡å‡†æ–¹æ³•
    ä½¿ç”¨ç­‰æ¸—å›å½’æ¥æ ¡å‡†ç½®ä¿¡åº¦
    """
    def __init__(self):
        self.calibrator = IsotonicRegression(out_of_bounds='clip')
    
    def fit(self, confidences: np.ndarray, labels: np.ndarray):
        """
        è®­ç»ƒç­‰æ¸—å›å½’å‚æ•°
        Args:
            confidences: åŸå§‹ç½®ä¿¡åº¦ [n_samples]
            labels: äºŒå…ƒæ ‡ç­¾ (0æˆ–1) [n_samples]
        """
        self.calibrator.fit(confidences, labels)
    
    def predict(self, confidences: np.ndarray) -> np.ndarray:
        """
        é¢„æµ‹æ ¡å‡†åçš„æ¦‚ç‡
        Args:
            confidences: åŸå§‹ç½®ä¿¡åº¦ [n_samples]
        Returns:
            æ ¡å‡†åçš„æ¦‚ç‡ [n_samples]
        """
        return self.calibrator.predict(confidences)


class ConfidenceCalibrator:
    """
    ç½®ä¿¡åº¦æ ¡å‡†å™¨ä¸»ç±»
    """
    def __init__(self, model: nn.Module, device: str = 'cuda'):
        self.model = model
        self.device = device
        self.temperature_scaler = None
        self.platt_scalers = {}  # æ¯ä¸ªç±»åˆ«ä¸€ä¸ªPlattç¼©æ”¾å™¨
        self.isotonic_scalers = {}  # æ¯ä¸ªç±»åˆ«ä¸€ä¸ªç­‰æ¸—å›å½’å™¨
        self.class_names = getattr(model, 'class_names', [])
        
    def calibrate_temperature_scaling(self, val_loader: DataLoader) -> float:
        """
        ä½¿ç”¨æ¸©åº¦ç¼©æ”¾è¿›è¡Œæ ¡å‡†
        Args:
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        Returns:
            æœ€ä¼˜æ¸©åº¦å€¼
        """
        print("ğŸŒ¡ï¸  å¼€å§‹æ¸©åº¦ç¼©æ”¾æ ¡å‡†...")
        
        # æ”¶é›†éªŒè¯é›†çš„logitså’Œæ ‡ç­¾
        all_logits = []
        all_labels = []
        
        self.model.eval()
        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                main_logits, aux_logits, clip_logits = self.model(images, use_aux=False)
                all_logits.append(main_logits)
                all_labels.append(labels)
        
        all_logits = torch.cat(all_logits, dim=0)
        all_labels = torch.cat(all_labels, dim=0)
        
        # è®­ç»ƒæ¸©åº¦ç¼©æ”¾ï¼Œä¿æŒåœ¨GPUä¸Š
        self.temperature_scaler = TemperatureScaling().to(self.device)
        optimal_temp = self.temperature_scaler.fit(all_logits, all_labels)
        
        print(f"âœ… æ¸©åº¦ç¼©æ”¾æ ¡å‡†å®Œæˆï¼Œæœ€ä¼˜æ¸©åº¦: {optimal_temp:.4f}")
        return optimal_temp
    
    def calibrate_platt_scaling(self, val_loader: DataLoader):
        """
        ä½¿ç”¨Plattç¼©æ”¾è¿›è¡Œæ ¡å‡†
        Args:
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        """
        print("ğŸ“Š å¼€å§‹Plattç¼©æ”¾æ ¡å‡†...")
        
        # æ”¶é›†æ¯ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦å’Œæ ‡ç­¾
        class_confidences = {i: [] for i in range(len(self.class_names))}
        class_labels = {i: [] for i in range(len(self.class_names))}
        
        self.model.eval()
        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                logits, _ = self.model(images)
                probs = torch.softmax(logits, dim=1)
                
                for i, (prob_vec, true_label) in enumerate(zip(probs, labels)):
                    for class_idx in range(len(self.class_names)):
                        confidence = prob_vec[class_idx].cpu().numpy()
                        is_correct = 1 if true_label.item() == class_idx else 0
                        
                        class_confidences[class_idx].append(confidence)
                        class_labels[class_idx].append(is_correct)
        
        # ä¸ºæ¯ä¸ªç±»åˆ«è®­ç»ƒPlattç¼©æ”¾å™¨
        for class_idx in range(len(self.class_names)):
            if len(set(class_labels[class_idx])) > 1:  # ç¡®ä¿æœ‰æ­£è´Ÿæ ·æœ¬
                scaler = PlattScaling()
                scaler.fit(np.array(class_confidences[class_idx]), 
                          np.array(class_labels[class_idx]))
                self.platt_scalers[class_idx] = scaler
                print(f"âœ… ç±»åˆ« {self.class_names[class_idx]} çš„Plattç¼©æ”¾å™¨è®­ç»ƒå®Œæˆ")
            else:
                print(f"âš ï¸  ç±»åˆ« {self.class_names[class_idx]} ç¼ºå°‘æ­£è´Ÿæ ·æœ¬ï¼Œè·³è¿‡Plattç¼©æ”¾")
    
    def calibrate_isotonic_regression(self, val_loader: DataLoader):
        """
        ä½¿ç”¨ç­‰æ¸—å›å½’è¿›è¡Œæ ¡å‡†
        Args:
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        """
        print("ğŸ“ˆ å¼€å§‹ç­‰æ¸—å›å½’æ ¡å‡†...")
        
        # æ”¶é›†æ¯ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦å’Œæ ‡ç­¾
        class_confidences = {i: [] for i in range(len(self.class_names))}
        class_labels = {i: [] for i in range(len(self.class_names))}
        
        self.model.eval()
        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                logits, _ = self.model(images)
                probs = torch.softmax(logits, dim=1)
                
                for i, (prob_vec, true_label) in enumerate(zip(probs, labels)):
                    for class_idx in range(len(self.class_names)):
                        confidence = prob_vec[class_idx].cpu().numpy()
                        is_correct = 1 if true_label.item() == class_idx else 0
                        
                        class_confidences[class_idx].append(confidence)
                        class_labels[class_idx].append(is_correct)
        
        # ä¸ºæ¯ä¸ªç±»åˆ«è®­ç»ƒç­‰æ¸—å›å½’å™¨
        for class_idx in range(len(self.class_names)):
            if len(set(class_labels[class_idx])) > 1:  # ç¡®ä¿æœ‰æ­£è´Ÿæ ·æœ¬
                scaler = IsotonicCalibration()
                scaler.fit(np.array(class_confidences[class_idx]), 
                          np.array(class_labels[class_idx]))
                self.isotonic_scalers[class_idx] = scaler
                print(f"âœ… ç±»åˆ« {self.class_names[class_idx]} çš„ç­‰æ¸—å›å½’å™¨è®­ç»ƒå®Œæˆ")
            else:
                print(f"âš ï¸  ç±»åˆ« {self.class_names[class_idx]} ç¼ºå°‘æ­£è´Ÿæ ·æœ¬ï¼Œè·³è¿‡ç­‰æ¸—å›å½’")
    
    def apply_temperature_scaling(self, logits: torch.Tensor) -> torch.Tensor:
        """
        åº”ç”¨æ¸©åº¦ç¼©æ”¾
        Args:
            logits: åŸå§‹logits
        Returns:
            æ ¡å‡†åçš„æ¦‚ç‡
        """
        if self.temperature_scaler is None:
            raise ValueError("æ¸©åº¦ç¼©æ”¾å™¨æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨calibrate_temperature_scaling")
        
        # ç¡®ä¿æ¸©åº¦ç¼©æ”¾å™¨åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        self.temperature_scaler = self.temperature_scaler.to(logits.device)
        return self.temperature_scaler(logits)
    
    def apply_platt_scaling(self, probs: torch.Tensor) -> torch.Tensor:
        """
        åº”ç”¨Plattç¼©æ”¾
        Args:
            probs: åŸå§‹æ¦‚ç‡åˆ†å¸ƒ
        Returns:
            æ ¡å‡†åçš„æ¦‚ç‡åˆ†å¸ƒ
        """
        if not self.platt_scalers:
            raise ValueError("Plattç¼©æ”¾å™¨æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨calibrate_platt_scaling")
        
        device = probs.device
        calibrated_probs = torch.zeros_like(probs)
        
        for class_idx in range(probs.shape[1]):
            if class_idx in self.platt_scalers:
                original_probs = probs[:, class_idx].cpu().numpy()
                calibrated = self.platt_scalers[class_idx].predict_proba(original_probs)
                calibrated_probs[:, class_idx] = torch.from_numpy(calibrated).to(device)
            else:
                calibrated_probs[:, class_idx] = probs[:, class_idx]
        
        # é‡æ–°å½’ä¸€åŒ–
        calibrated_probs = calibrated_probs / calibrated_probs.sum(dim=1, keepdim=True)
        return calibrated_probs
    
    def apply_isotonic_regression(self, probs: torch.Tensor) -> torch.Tensor:
        """
        åº”ç”¨ç­‰æ¸—å›å½’
        Args:
            probs: åŸå§‹æ¦‚ç‡åˆ†å¸ƒ
        Returns:
            æ ¡å‡†åçš„æ¦‚ç‡åˆ†å¸ƒ
        """
        if not self.isotonic_scalers:
            raise ValueError("ç­‰æ¸—å›å½’å™¨æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨calibrate_isotonic_regression")
        
        device = probs.device
        calibrated_probs = torch.zeros_like(probs)
        
        for class_idx in range(probs.shape[1]):
            if class_idx in self.isotonic_scalers:
                original_probs = probs[:, class_idx].cpu().numpy()
                calibrated = self.isotonic_scalers[class_idx].predict(original_probs)
                calibrated_probs[:, class_idx] = torch.from_numpy(calibrated).to(device)
            else:
                calibrated_probs[:, class_idx] = probs[:, class_idx]
        
        # é‡æ–°å½’ä¸€åŒ–
        calibrated_probs = calibrated_probs / calibrated_probs.sum(dim=1, keepdim=True)
        return calibrated_probs


def calculate_ece(confidences: np.ndarray, accuracies: np.ndarray, 
                  n_bins: int = 10) -> float:
    """
    è®¡ç®—æœŸæœ›æ ¡å‡†è¯¯å·® (Expected Calibration Error)
    Args:
        confidences: ç½®ä¿¡åº¦æ•°ç»„
        accuracies: å‡†ç¡®ç‡æ•°ç»„ (0æˆ–1)
        n_bins: åˆ†ç®±æ•°é‡
    Returns:
        ECEå€¼
    """
    bin_boundaries = np.linspace(0, 1, n_bins + 1)
    bin_lowers = bin_boundaries[:-1]
    bin_uppers = bin_boundaries[1:]
    
    ece = 0
    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
        # æ‰¾åˆ°åœ¨å½“å‰binä¸­çš„æ ·æœ¬
        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)
        prop_in_bin = in_bin.mean()
        
        if prop_in_bin > 0:
            accuracy_in_bin = accuracies[in_bin].mean()
            avg_confidence_in_bin = confidences[in_bin].mean()
            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin
    
    return ece


def calculate_mce(confidences: np.ndarray, accuracies: np.ndarray, 
                  n_bins: int = 10) -> float:
    """
    è®¡ç®—æœ€å¤§æ ¡å‡†è¯¯å·® (Maximum Calibration Error)
    Args:
        confidences: ç½®ä¿¡åº¦æ•°ç»„
        accuracies: å‡†ç¡®ç‡æ•°ç»„ (0æˆ–1)
        n_bins: åˆ†ç®±æ•°é‡
    Returns:
        MCEå€¼
    """
    bin_boundaries = np.linspace(0, 1, n_bins + 1)
    bin_lowers = bin_boundaries[:-1]
    bin_uppers = bin_boundaries[1:]
    
    mce = 0
    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
        # æ‰¾åˆ°åœ¨å½“å‰binä¸­çš„æ ·æœ¬
        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)
        prop_in_bin = in_bin.mean()
        
        if prop_in_bin > 0:
            accuracy_in_bin = accuracies[in_bin].mean()
            avg_confidence_in_bin = confidences[in_bin].mean()
            mce = max(mce, np.abs(avg_confidence_in_bin - accuracy_in_bin))
    
    return mce


def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    font_paths = [
        '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
        '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',
        './fonts/NotoSansCJK-Regular.ttc',
        './fonts/NotoSansSC-Regular.ttf',
        '/System/Library/Fonts/PingFang.ttc',
        'C:/Windows/Fonts/msyh.ttc',
        'C:/Windows/Fonts/simhei.ttf'
    ]
    
    for font_path in font_paths:
        if os.path.exists(font_path):
            try:
                font_prop = fm.FontProperties(fname=font_path)
                fm.fontManager.addfont(font_path)
                font_name = font_prop.get_name()
                plt.rcParams['font.family'] = font_name
                plt.rcParams['axes.unicode_minus'] = False
                return True
            except Exception:
                continue
    
    # å¤‡é€‰æ–¹æ¡ˆ
    chinese_fonts = ['Noto Sans CJK SC', 'WenQuanYi Micro Hei', 'SimHei', 
                     'Microsoft YaHei', 'PingFang SC']
    for font_name in chinese_fonts:
        try:
            plt.rcParams['font.family'] = font_name
            plt.rcParams['axes.unicode_minus'] = False
            return True
        except Exception:
            continue
    
    plt.rcParams['font.family'] = ['sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
    return False


def plot_calibration_comparison(original_results: Dict, 
                              calibrated_results: Dict,
                              save_path: str = './result/calibration_comparison.png'):
    """
    ç»˜åˆ¶æ ¡å‡†å‰åçš„å¯¹æ¯”å›¾
    Args:
        original_results: åŸå§‹ç»“æœå­—å…¸
        calibrated_results: æ ¡å‡†åç»“æœå­—å…¸
        save_path: ä¿å­˜è·¯å¾„
    """
    font_available = setup_chinese_font()
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    methods = ['temperature', 'platt', 'isotonic']
    method_names = ['æ¸©åº¦ç¼©æ”¾', 'Plattç¼©æ”¾', 'ç­‰æ¸—å›å½’'] if font_available else \
                   ['Temperature', 'Platt', 'Isotonic']
    
    # åŸå§‹ç»“æœ
    orig_conf = np.array([r['confidence'] for r in original_results['results']])
    orig_acc = np.array([r['is_correct'] for r in original_results['results']], dtype=int)
    
    for i, (method, method_name) in enumerate(zip(methods, method_names)):
        if method not in calibrated_results:
            continue
            
        calib_conf = np.array([r['confidence'] for r in calibrated_results[method]['results']])
        calib_acc = np.array([r['is_correct'] for r in calibrated_results[method]['results']], dtype=int)
        
        # æ ¡å‡†å›¾ (ä¸Šæ’)
        ax1 = axes[0, i]
        
        # ç»˜åˆ¶åŸå§‹å’Œæ ¡å‡†åçš„æ ¡å‡†æ›²çº¿
        n_bins = 10
        bin_boundaries = np.linspace(0, 1, n_bins + 1)
        bin_lowers = bin_boundaries[:-1]
        bin_uppers = bin_boundaries[1:]
        
        orig_bin_acc = []
        orig_bin_conf = []
        calib_bin_acc = []
        calib_bin_conf = []
        bin_centers = []
        
        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
            bin_center = (bin_lower + bin_upper) / 2
            bin_centers.append(bin_center)
            
            # åŸå§‹ç»“æœ
            in_bin_orig = (orig_conf > bin_lower) & (orig_conf <= bin_upper)
            if in_bin_orig.sum() > 0:
                orig_bin_acc.append(orig_acc[in_bin_orig].mean())
                orig_bin_conf.append(orig_conf[in_bin_orig].mean())
            else:
                orig_bin_acc.append(0)
                orig_bin_conf.append(bin_center)
            
            # æ ¡å‡†åç»“æœ
            in_bin_calib = (calib_conf > bin_lower) & (calib_conf <= bin_upper)
            if in_bin_calib.sum() > 0:
                calib_bin_acc.append(calib_acc[in_bin_calib].mean())
                calib_bin_conf.append(calib_conf[in_bin_calib].mean())
            else:
                calib_bin_acc.append(0)
                calib_bin_conf.append(bin_center)
        
        # ç»˜åˆ¶æ ¡å‡†æ›²çº¿
        ax1.plot([0, 1], [0, 1], 'k--', label='å®Œç¾æ ¡å‡†' if font_available else 'Perfect Calibration')
        ax1.plot(orig_bin_conf, orig_bin_acc, 'ro-', label='åŸå§‹' if font_available else 'Original')
        ax1.plot(calib_bin_conf, calib_bin_acc, 'bo-', label='æ ¡å‡†å' if font_available else 'Calibrated')
        
        ax1.set_xlabel('ç½®ä¿¡åº¦' if font_available else 'Confidence')
        ax1.set_ylabel('å‡†ç¡®ç‡' if font_available else 'Accuracy')
        ax1.set_title(f'{method_name} æ ¡å‡†æ›²çº¿' if font_available else f'{method_name} Calibration')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_xlim(0, 1)
        ax1.set_ylim(0, 1)
        
        # ç½®ä¿¡åº¦åˆ†å¸ƒå¯¹æ¯” (ä¸‹æ’)
        ax2 = axes[1, i]
        
        ax2.hist(orig_conf, bins=20, alpha=0.5, color='red', 
                label=f'åŸå§‹ (ECE: {calculate_ece(orig_conf, orig_acc):.3f})' if font_available else 
                      f'Original (ECE: {calculate_ece(orig_conf, orig_acc):.3f})')
        ax2.hist(calib_conf, bins=20, alpha=0.5, color='blue',
                label=f'æ ¡å‡†å (ECE: {calculate_ece(calib_conf, calib_acc):.3f})' if font_available else
                      f'Calibrated (ECE: {calculate_ece(calib_conf, calib_acc):.3f})')
        
        ax2.set_xlabel('ç½®ä¿¡åº¦' if font_available else 'Confidence')
        ax2.set_ylabel('æ•°é‡' if font_available else 'Count')
        ax2.set_title(f'{method_name} ç½®ä¿¡åº¦åˆ†å¸ƒ' if font_available else f'{method_name} Distribution')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"âœ… æ ¡å‡†å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")


def save_calibration_results(original_results: Dict, 
                           calibrated_results: Dict,
                           save_path: str = './result/calibration_results.json'):
    """
    ä¿å­˜æ ¡å‡†ç»“æœ
    Args:
        original_results: åŸå§‹ç»“æœ
        calibrated_results: æ ¡å‡†åç»“æœ
        save_path: ä¿å­˜è·¯å¾„
    """
    # è®¡ç®—å„ç§æŒ‡æ ‡
    orig_conf = np.array([r['confidence'] for r in original_results['results']])
    orig_acc = np.array([r['is_correct'] for r in original_results['results']], dtype=int)
    
    results_summary = {
        'original': {
            'accuracy': original_results['accuracy'],
            'ece': calculate_ece(orig_conf, orig_acc),
            'mce': calculate_mce(orig_conf, orig_acc),
            'avg_confidence': float(orig_conf.mean()),
            'confidence_std': float(orig_conf.std())
        }
    }
    
    for method in ['temperature', 'platt', 'isotonic']:
        if method in calibrated_results:
            calib_conf = np.array([r['confidence'] for r in calibrated_results[method]['results']])
            calib_acc = np.array([r['is_correct'] for r in calibrated_results[method]['results']], dtype=int)
            
            results_summary[method] = {
                'accuracy': calibrated_results[method]['accuracy'],
                'ece': calculate_ece(calib_conf, calib_acc),
                'mce': calculate_mce(calib_conf, calib_acc),
                'avg_confidence': float(calib_conf.mean()),
                'confidence_std': float(calib_conf.std())
            }
    
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æ ¡å‡†ç»“æœå·²ä¿å­˜: {save_path}")
    return results_summary
